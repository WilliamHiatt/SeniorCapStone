{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9dccd1a",
   "metadata": {},
   "source": [
    "# Latent Probability Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01049288",
   "metadata": {},
   "source": [
    "If you are running this for the first time you may need to use the following commands before continuing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ba699a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1224983346.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_30416\\1224983346.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip3 install pandas==1.3.5\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip3 install pandas==1.3.5\n",
    "pip3 install spacy==3.2.0\n",
    "pip3 install spacytextblob\n",
    "python3 -m spacy download en_core_web_sm\n",
    "\n",
    "pip3 install newspaper3k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a2232",
   "metadata": {},
   "source": [
    "Spacy: Used for NLP and has the machine learning module\n",
    "    \n",
    "SpacyTextBlob: Used for the sentiment analysis\n",
    "    \n",
    "Pandas: Stores the data as a dataframe table\n",
    "    \n",
    "NewsPaper: Used for web scraping\n",
    "    \n",
    "Requests: Makes the connection to the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "fae0f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "import pandas as pd\n",
    "import requests\n",
    "from newspaper import Article\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67afdeff",
   "metadata": {},
   "source": [
    "IMPORTANT: If you want to try re-runing after making some code changes or want to \n",
    "run a new .csv file through the code block below and the one a couple down with the\n",
    " rerun note will need to be ran again for the analysis to work correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "4d78c510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x13a4ecf20b0>"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading our two pipelines\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b787c3f5",
   "metadata": {},
   "source": [
    "IMPORTANT: Insert the .csv file you want to be read below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "4e23034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = \"urls9.csv\"\n",
    "wordCountFilter = 500\n",
    "social_starts_with = [\"https://www.youtube.com\", \"https://youtu.be\", \"https://www.facebook.com\", \n",
    "                      \"https://twitter.com\", \"https://gettr.com/\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "51cde877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun\n",
    "# Using panda to load in our .csv file\n",
    "df = pd.read_csv(csvFile) # File we are checking\n",
    "urls = df[\"Address\"].tolist() # Column name we are checking\n",
    "all_text_gathered = []\n",
    "all_articles = ''\n",
    "scentence_list = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa006c6",
   "metadata": {},
   "source": [
    "Following code block used for scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "1aa273e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeData(url):\n",
    "    try:\n",
    "        for y in social_starts_with:\n",
    "            if(url.startswith(y)):\n",
    "                isSocial = True\n",
    "            else:\n",
    "                isSocial = False\n",
    "        if(isSocial != True):\n",
    "            article = Article(url)\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            \n",
    "            page_text = (article.text).lower()\n",
    "            page_text = page_text.strip().replace(\"  \",\"\")\n",
    "            page_text = \"\".join([s for s in page_text.splitlines(True) if s.strip(\"\\r\\n\")])\n",
    "            \n",
    "            strLength = np.char.count(page_text, ' ') + 1\n",
    "            if(strLength < wordCountFilter):\n",
    "                page_text = \"PARERROR: Not enough words: \" + str(strLength) + \" < \" + str(wordCountFilter)\n",
    "                            \n",
    "            \n",
    "        else:\n",
    "            page_text = \"PARERROR: SocialError\"\n",
    "    except:\n",
    "        page_text = \"PARERROR: ErrorCouldntParse\"\n",
    "        \n",
    "    return page_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a45b100",
   "metadata": {},
   "source": [
    "This is the template used for adding new models/tools to the pipeline. Instructions are inside the function marked as comments. No need to run this code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a17013d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (602059371.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [255]\u001b[1;36m\u001b[0m\n\u001b[1;33m    if(len(dictionary) == 0)\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "def functionName(text, dictionary, url):\n",
    "    # This function needs to return a dictionary for what values you want in the\n",
    "    # dataframe. For example if we want our columns to be \"sentiment score\" \n",
    "    # and \"positive or negative\" we would return \n",
    "    # {'sentiment score': 'score', 'positive or negative': 'positive'}\n",
    "    if(len(dictionary) == 0)\n",
    "        dictionary = # define dicitonary based on above\n",
    "    if(text[0:7] != 'PARERROR'):\n",
    "        # Run analysis here\n",
    "    else:\n",
    "        # Throws this if there was some sort of error in the web scraping\n",
    "        # Append the text to whereever the \"outcome\" would be appended\n",
    "        # For example for sentiment analysis, instead of appending a sentiment score\n",
    "        # Append the error\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "80fc650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentAnalysis(text, dictionary, url):\n",
    "    if(len(dictionary) == 0):\n",
    "        dictionary = {\n",
    "            \"URL\": [],\n",
    "            \"Sentiment Score\": [],\n",
    "            \"Sentiment Label\": [],\n",
    "            \"Subjectivity Score\": [],\n",
    "            \"Positive Words\": [],\n",
    "            \"Negative Words\": []\n",
    "            }\n",
    "    if(text[0:8] != \"PARERROR\"):\n",
    "        # Start the sentiment analysis now\n",
    "        dictionary[\"URL\"].append(url)\n",
    "        doc = nlp(text)\n",
    "        sentiment = doc._.blob.polarity\n",
    "        sentiment = round(sentiment,2)\n",
    "        subjectivity = doc._.blob.subjectivity\n",
    "        subjectivity = round(subjectivity,2)\n",
    "\n",
    "        # Gives positive or negative label\n",
    "        if sentiment >= 0.033 and sentiment <= 0.043:\n",
    "            sent_label = \"Neutral\"\n",
    "        elif sentiment > 0.043 and sentiment < 0.143:\n",
    "            sent_label = \"Neutral Positive\"\n",
    "        elif sentiment > 0.143:\n",
    "            sent_label = \"Positive\"\n",
    "        elif sentiment < 0.033 and sentiment > -0.062:\n",
    "            sent_label = \"Neutral Negative\"\n",
    "        elif sentiment < -0.062:\n",
    "            sent_label = \"Negative\"\n",
    "\n",
    "        dictionary[\"Sentiment Label\"].append(sent_label)\n",
    "        dictionary[\"Sentiment Score\"].append(sentiment)\n",
    "        dictionary[\"Subjectivity Score\"].append(subjectivity)\n",
    "\n",
    "        positive_words = []\n",
    "        negative_words = []\n",
    "\n",
    "        for x in doc._.blob.sentiment_assessments.assessments:\n",
    "          if x[1] > 0:\n",
    "            positive_words.append(x[0][0])\n",
    "          elif x[1] < 0:\n",
    "            negative_words.append(x[0][0])\n",
    "          else:\n",
    "            pass\n",
    "\n",
    "        dictionary[\"Positive Words\"].append(', '.join(set(positive_words)))\n",
    "        dictionary[\"Negative Words\"].append(', '.join(set(negative_words)))\n",
    "    \n",
    "    else:\n",
    "        dictionary[\"URL\"].append(url)\n",
    "        dictionary[\"Sentiment Label\"].append(text)\n",
    "        dictionary[\"Sentiment Score\"].append(0.0)\n",
    "        dictionary[\"Subjectivity Score\"].append(0.0)\n",
    "\n",
    "        positive_words = []\n",
    "        negative_words = []\n",
    "\n",
    "        dictionary[\"Positive Words\"].append(', '.join(set(positive_words)))\n",
    "        dictionary[\"Negative Words\"].append(', '.join(set(negative_words)))\n",
    "    \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5876ee62",
   "metadata": {},
   "source": [
    "Simple method to create data frames from dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "a960bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionaryToDataFrame(dictionary):\n",
    "    return pd.DataFrame(dictionary)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdc4425",
   "metadata": {},
   "source": [
    "Returns a list of the article at a sentence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "3e878fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenceLevel(parsedText):\n",
    "    returnList = []\n",
    "    newText = nlp(parsedText)\n",
    "    for sent in newText.sents:\n",
    "        returnList.append(sent)\n",
    "    \n",
    "    return returnList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05102c4",
   "metadata": {},
   "source": [
    "Gets the average sentiment of all scentences combined in an article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "9cef1890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageSentenceLevel(sentenceLevDic, keysToBeAveraged):\n",
    "    for x in sentenceLevDic:\n",
    "        if y in keysToBeAveraged:\n",
    "            num = len(sentenceLevDic[y])\n",
    "            sentenceLevDic[y] = sum(sentenceLevDic[y]) / num\n",
    "    \n",
    "    return sentenceLevDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a494e1c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3329120566.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [18]\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def averageSentimentScore(listOfDictionaries):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fabe01",
   "metadata": {},
   "source": [
    "# This is the pipeline. All code is called and ran through here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "7ae169b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Sentiment Label</th>\n",
       "      <th>Subjectivity Score</th>\n",
       "      <th>Positive Words</th>\n",
       "      <th>Negative Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.thegatewaypundit.com/2022/05/world...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Neutral Positive</td>\n",
       "      <td>0.28</td>\n",
       "      <td>free, confident, new, major, supporting, not, ...</td>\n",
       "      <td>needless, other, single, absolutely, past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://gettr.com/post/ptt4ta7c84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PARERROR: SocialError</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://komonews.com/news/coronavirus/if-covid...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PARERROR: Not enough words: 52 &lt; 500</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.lewrockwell.com/2018/11/no_author/...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Neutral Positive</td>\n",
       "      <td>0.41</td>\n",
       "      <td>new, many, newly, major, no, whole, old, promi...</td>\n",
       "      <td>military, killed, active, typically, worse, fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://nation.com.pk/08-Apr-2021/russia-offer...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>Neutral Positive</td>\n",
       "      <td>0.28</td>\n",
       "      <td>significant, new, special, natural, ready, dir...</td>\n",
       "      <td>actively, military, mainly, foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://barrie.ctvnews.ca/cfb-borden-based-mil...</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>Neutral Negative</td>\n",
       "      <td>0.38</td>\n",
       "      <td>not, unique, first, fine, good, full, willingly</td>\n",
       "      <td>military, due, very, not, wrong, base, guilty,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.reuters.com/world/us/us-army-disch...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PARERROR: Not enough words: 236 &lt; 500</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.dailysabah.com/world/europe/sweden...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PARERROR: Not enough words: 271 &lt; 500</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.military.com/daily-news/2022/11/01...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>Neutral Positive</td>\n",
       "      <td>0.46</td>\n",
       "      <td>most, new, nearly, general, best, fly, latest,...</td>\n",
       "      <td>approximately, military, active, base, limited...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  Sentiment Score  \\\n",
       "0  https://www.thegatewaypundit.com/2022/05/world...             0.05   \n",
       "1                  https://gettr.com/post/ptt4ta7c84             0.00   \n",
       "2  https://komonews.com/news/coronavirus/if-covid...             0.00   \n",
       "3  https://www.lewrockwell.com/2018/11/no_author/...             0.10   \n",
       "4  https://nation.com.pk/08-Apr-2021/russia-offer...             0.07   \n",
       "5  https://barrie.ctvnews.ca/cfb-borden-based-mil...            -0.02   \n",
       "6  https://www.reuters.com/world/us/us-army-disch...             0.00   \n",
       "7  https://www.dailysabah.com/world/europe/sweden...             0.00   \n",
       "8  https://www.military.com/daily-news/2022/11/01...             0.07   \n",
       "\n",
       "                         Sentiment Label  Subjectivity Score  \\\n",
       "0                       Neutral Positive                0.28   \n",
       "1                  PARERROR: SocialError                0.00   \n",
       "2   PARERROR: Not enough words: 52 < 500                0.00   \n",
       "3                       Neutral Positive                0.41   \n",
       "4                       Neutral Positive                0.28   \n",
       "5                       Neutral Negative                0.38   \n",
       "6  PARERROR: Not enough words: 236 < 500                0.00   \n",
       "7  PARERROR: Not enough words: 271 < 500                0.00   \n",
       "8                       Neutral Positive                0.46   \n",
       "\n",
       "                                      Positive Words  \\\n",
       "0  free, confident, new, major, supporting, not, ...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  new, many, newly, major, no, whole, old, promi...   \n",
       "4  significant, new, special, natural, ready, dir...   \n",
       "5    not, unique, first, fine, good, full, willingly   \n",
       "6                                                      \n",
       "7                                                      \n",
       "8  most, new, nearly, general, best, fly, latest,...   \n",
       "\n",
       "                                      Negative Words  \n",
       "0          needless, other, single, absolutely, past  \n",
       "1                                                     \n",
       "2                                                     \n",
       "3  military, killed, active, typically, worse, fr...  \n",
       "4                actively, military, mainly, foreign  \n",
       "5  military, due, very, not, wrong, base, guilty,...  \n",
       "6                                                     \n",
       "7                                                     \n",
       "8  approximately, military, active, base, limited...  "
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loops through our URLS and scraps the data\n",
    "# Put all empty dictionaries here\n",
    "sentimentDic = {}\n",
    "    \n",
    "for count, x in enumerate(urls):\n",
    "    if(count % 10 == 0):\n",
    "        print(str(count))\n",
    "\n",
    "    url = x\n",
    "\n",
    "    # Send the URL to get scraped\n",
    "    page_text = scrapeData(x)\n",
    "    # All articles will have a long string of all the text that has been scraped\n",
    "    all_articles = all_articles + \" \" +  page_text\n",
    "    \n",
    "    # Puts the article into a list of all the sentences in the article\n",
    "    sentenceList = sentenceLevel(page_text)\n",
    "\n",
    "    # Runs sentiment analysis. Will need to make a new function and a new dictionary\n",
    "    # for each type of analysis we want to run. Will pass in the page_text, the dic, and\n",
    "    # x (the url)\n",
    "    sentimentDic = sentimentAnalysis(page_text, sentimentDic, url)\n",
    "        \n",
    "        \n",
    "        \n",
    "#print(\"The average sentiment score was: \" + str(sum(url_sent_score) / len(url_sent_score)))\n",
    "#print(\"The average subjectivity score was: \" + str(sum(url_subj_score) / len(url_subj_score)))\n",
    "\n",
    "# For each analysis we run we need to then convert that dictionary with the following method\n",
    "sentDic = dictionaryToDataFrame(sentimentDic)\n",
    "sentDic\n",
    "# Used if we want to convert it to a .csv sentDic.to_csv(\"sentiment130.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd69accd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
