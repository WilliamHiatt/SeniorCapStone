{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82ad8d95",
   "metadata": {},
   "source": [
    "Playground Used to Test spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6464475",
   "metadata": {},
   "source": [
    "spaCy overview:\n",
    "\n",
    "Designed for production use to understand large volumes of text. Can be used to build information extraction or NL understanding systems, or to pre-process text for deep learning.\n",
    "\n",
    "Spacy text blop allows for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6cdb61",
   "metadata": {},
   "source": [
    "Used to print the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91c2b2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n"
     ]
    }
   ],
   "source": [
    "# Import spaCy\n",
    "import spacy\n",
    "\n",
    "# Create the English nlp object\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Process a text\n",
    "doc = nlp(\"This is a sentence.\")\n",
    "\n",
    "# Print the document text\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10332a43",
   "metadata": {},
   "source": [
    "Part 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab35ac00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n"
     ]
    }
   ],
   "source": [
    "# Import spaCy and create the English nlp object\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
    "\n",
    "# Select the first token\n",
    "first_token = doc[0]\n",
    "\n",
    "# Print the first token's text\n",
    "print(first_token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f924f",
   "metadata": {},
   "source": [
    "Part3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5aabaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree kangaroos\n",
      "tree kangaroos and narwhals\n"
     ]
    }
   ],
   "source": [
    "# Import spaCy and create the English nlp object\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
    "\n",
    "# A slice of the Doc for \"tree kangaroos\"\n",
    "tree_kangaroos = doc[2:4]\n",
    "print(tree_kangaroos.text)\n",
    "\n",
    "# A slice of the Doc for \"tree kangaroos and narwhals\" (without the \".\")\n",
    "tree_kangaroos_and_narwhals = doc[2:6]\n",
    "print(tree_kangaroos_and_narwhals.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5190b396",
   "metadata": {},
   "source": [
    "Finding percent signs in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f65b03b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage found: 60\n",
      "Percentage found: 4\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(\n",
    "    \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n",
    "    \"Now less than 4% are.\"\n",
    ")\n",
    "\n",
    "# Iterate over the tokens in the doc\n",
    "for token in doc:\n",
    "    # Check if the token resembles a number\n",
    "    if token.like_num:\n",
    "        # Get the next token in the document\n",
    "        next_token = doc[token.i + 1]\n",
    "        # Check if the next token's text equals \"%\"\n",
    "        if next_token.text == \"%\":\n",
    "            print(\"Percentage found:\", token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78817229",
   "metadata": {},
   "source": [
    "Loading Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01854eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the \"en_core_web_sm\" pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the document text\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6636ee0",
   "metadata": {},
   "source": [
    "Using the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d49edf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It          PRON      nsubj     \n",
      "’s          VERB      ccomp     \n",
      "official    NOUN      acomp     \n",
      ":           PUNCT     punct     \n",
      "Apple       PROPN     nsubj     \n",
      "is          AUX       ROOT      \n",
      "the         DET       det       \n",
      "first       ADJ       amod      \n",
      "U.S.        PROPN     nmod      \n",
      "public      ADJ       amod      \n",
      "company     NOUN      attr      \n",
      "to          PART      aux       \n",
      "reach       VERB      relcl     \n",
      "a           DET       det       \n",
      "$           SYM       quantmod  \n",
      "1           NUM       compound  \n",
      "trillion    NUM       nummod    \n",
      "market      NOUN      compound  \n",
      "value       NOUN      dobj      \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    # This is for formatting only\n",
    "    print(f\"{token_text:<12}{token_pos:<10}{token_dep:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4db2e97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "first ORDINAL\n",
      "U.S. GPE\n",
      "$1 trillion MONEY\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the predicted entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and its label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72c3c5a",
   "metadata": {},
   "source": [
    "You can get missing entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15e15f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "Missing entity: iPhone X\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Upcoming iPhone X release date leaked as Apple reveals pre-orders\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and label\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "# Get the span for \"iPhone X\"\n",
    "iphone_x = doc[1:3]\n",
    "\n",
    "# Print the span text\n",
    "print(\"Missing entity:\", iphone_x.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659d53ad",
   "metadata": {},
   "source": [
    "Messing with the matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c8e42e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: ['iPhone X']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Import the Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Upcoming iPhone X release date leaked as Apple reveals pre-orders\")\n",
    "\n",
    "# Initialize the Matcher with the shared vocabulary\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Create a pattern matching two tokens: \"iPhone\" and \"X\"\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "matcher.add(\"IPHONE_X_PATTERN\", [pattern])\n",
    "\n",
    "# Use the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1c7d6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 5\n",
      "Match found: beautiful design\n",
      "Match found: smart search\n",
      "Match found: automatic labels\n",
      "Match found: optional voice\n",
      "Match found: optional voice responses\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    \"Features of the app include a beautiful design, smart search, automatic \"\n",
    "    \"labels and optional voice responses.\"\n",
    ")\n",
    "\n",
    "# Write a pattern for adjective plus one or two nouns\n",
    "pattern = [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}, {\"POS\": \"NOUN\", \"OP\": \"?\"}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add(\"ADJ_NOUN_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1726a49a",
   "metadata": {},
   "source": [
    "Creating a doc and inserting spaces in desired areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2feb0472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go, get started!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Import the Doc class\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# Desired text: \"Go, get started!\"\n",
    "words = [\"Go\", \",\", \"get\", \"started\", \"!\"]\n",
    "spaces = [False, True, True, False, False]\n",
    "\n",
    "# Create a Doc from the words and spaces\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f07219cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, really?!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Import the Doc class\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# Desired text: \"Oh, really?!\"\n",
    "words = [\"Oh\", \",\", \"really\", \"?\", \"!\"]\n",
    "spaces = [False, True, False, False, False]\n",
    "\n",
    "# Create a Doc from the words and spaces\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7da3b",
   "metadata": {},
   "source": [
    "spaCy with textblob for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26ff662b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.125\n",
      "0.9\n",
      "[(['really', 'horrible'], -1.0, 1.0, None), (['worst', '!'], -1.0, 1.0, None), (['really', 'good'], 0.7, 0.6000000000000001, None), (['happy'], 0.8, 1.0, None)]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "text = \"I had a really horrible day. It was the worst day ever! But every now and then I have a really good day that makes me happy.\"\n",
    "nlp.add_pipe(\"spacytextblob\")\n",
    "doc = nlp(text)\n",
    "\n",
    "print(doc._.blob.polarity)\n",
    "# -0.125\n",
    "\n",
    "print(doc._.blob.subjectivity)\n",
    "# 0.9\n",
    "\n",
    "print(doc._.blob.sentiment_assessments.assessments)\n",
    "# [(['really', 'horrible'], -1.0, 1.0, None), (['worst', '!'], -1.0, 1.0, None), (['really', 'good'], 0.7, 0.6000000000000001, None), (['happy'], 0.8, 1.0, None)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28de734b",
   "metadata": {},
   "source": [
    "Another example of them being used together\n",
    "Code grabbed from this tutorial: https://importsem.com/evaluate-sentiment-analysis-in-bulk-with-spacy-and-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4f1109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Sentiment Label</th>\n",
       "      <th>Positive Words</th>\n",
       "      <th>Negative Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.nbcnews.com/news/us-news/ohio-dera...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>Positive</td>\n",
       "      <td>striking, legal, successfully, large, able, ne...</td>\n",
       "      <td>dead, down, killed, terrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.cnn.com/2023/02/28/health/moderate...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://abcnews.go.com/US/chicago-cop-shot-kil...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Address  Sentiment Score  \\\n",
       "0  https://www.nbcnews.com/news/us-news/ohio-dera...             0.09   \n",
       "1  https://www.cnn.com/2023/02/28/health/moderate...             0.09   \n",
       "2  https://abcnews.go.com/US/chicago-cop-shot-kil...             0.09   \n",
       "\n",
       "  Sentiment Label                                     Positive Words  \\\n",
       "0        Positive  striking, legal, successfully, large, able, ne...   \n",
       "1        Positive                                                NaN   \n",
       "2        Positive                                                NaN   \n",
       "\n",
       "                 Negative Words  \n",
       "0  dead, down, killed, terrible  \n",
       "1                           NaN  \n",
       "2                           NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Loading the two pipelines. The first is for spacy NLP and the second is for\n",
    "# textblob sentiment analysis\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "# Send in our urls. Then create empty lists for the scores\n",
    "df = pd.read_csv(\"urls.csv\")\n",
    "urls = df[\"Address\"].tolist()\n",
    "url_sent_score = []\n",
    "url_sent_label = []\n",
    "total_pos = []\n",
    "total_neg = []\n",
    "\n",
    "# Interate through the URL list\n",
    "for count, x in enumerate(urls):\n",
    "    url = x\n",
    "\n",
    "    # user-agent is used to help with bot blocking\n",
    "    headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36'}\n",
    "    res = requests.get(url,headers=headers)\n",
    "    html_page = res.text\n",
    "\n",
    "    #beautiful soup is used for parsing\n",
    "    soup = BeautifulSoup(html_page, 'html.parser')\n",
    "    for script in soup([\"script\", \"style\",\"meta\",\"label\",\"header\",\"footer\"]):\n",
    "        script.decompose()\n",
    "        page_text = (soup.get_text()).lower()\n",
    "        page_text = page_text.strip().replace(\"  \",\"\") #Getting rid of white spaces\n",
    "        page_text = \"\".join([s for s in page_text.splitlines(True) if s.strip(\"\\r\\n\")])\n",
    "\n",
    "        # Loading into spacy\n",
    "        doc = nlp(page_text)\n",
    "        sentiment = doc._.blob.polarity\n",
    "        sentiment = round(sentiment,2)\n",
    "\n",
    "        # Setting labels\n",
    "        if sentiment > 0:\n",
    "          sent_label = \"Positive\"\n",
    "        else:\n",
    "          sent_label = \"Negative\"\n",
    "\n",
    "        url_sent_label.append(sent_label)\n",
    "        url_sent_score.append(sentiment)\n",
    "\n",
    "# Empty lists to store words\n",
    "positive_words = []\n",
    "negative_words = []\n",
    "\n",
    "# This loops through a tuple object with the word, polarity (sentiment score), and subjectivity\n",
    "for x in doc._.blob.sentiment_assessments.assessments:\n",
    "  if x[1] > 0: # Evaluates the score (second item in tuple)\n",
    "    positive_words.append(x[0][0])\n",
    "  elif x[1] < 0:\n",
    "    negative_words.append(x[0][0])\n",
    "  else:\n",
    "    pass\n",
    "\n",
    "# Removes duplicates and creates a single long string\n",
    "total_pos.append(', '.join(set(positive_words)))\n",
    "total_neg.append(', '.join(set(negative_words)))\n",
    "\n",
    "# Attatching everything to the dataframe\n",
    "# Had to alter this part. Didn't originally have the pd.Series, only the stuff in ()\n",
    "df[\"Sentiment Score\"] = pd.Series(url_sent_score)\n",
    "df[\"Sentiment Label\"] = pd.Series(url_sent_label)\n",
    "df[\"Positive Words\"] = pd.Series(total_pos)\n",
    "df[\"Negative Words\"] = pd.Series(total_neg)\n",
    "\n",
    "#optional export to CSV\n",
    "df.to_csv(\"sentiment.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3658e926",
   "metadata": {},
   "source": [
    "Another tutorial on spacy + textblob. Tutorial followed from youtube video: https://www.youtube.com/watch?v=6bg-TNoT5_Y&ab_channel=JCharisTech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4805c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load NLP\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e91140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x2c03d9c2620>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x2c03d9c2b00>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x2c03d9b0200>),\n",
       " ('senter', <spacy.pipeline.senter.SentenceRecognizer at 0x2c03d84e680>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x2c03d8b35c0>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x2c03db75e80>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x2c03d9b03c0>),\n",
       " ('spacytextblob',\n",
       "  <spacytextblob.spacytextblob.SpacyTextBlob at 0x2c03db6bd30>)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore NLP pipeline components\n",
    "nlp.components # can also use nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a00961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x2c040a427a0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x2c040a41840>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x2c040996dc0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x2c0408e0680>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x2c0408dd200>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x2c0409967a0>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b945b3b8",
   "metadata": {},
   "source": [
    "# Using spacy textblob: Sentiment Analysis using textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a7ebd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacytextblob.spacytextblob import SpacyTextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa572db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x2c03da65150>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding SpacyTextblob to NLP Pipeline\n",
    "nlp.add_pipe(\"spacytextblob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49ac2602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x2c040a427a0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x2c040a41840>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x2c040996dc0>),\n",
       " ('senter', <spacy.pipeline.senter.SentenceRecognizer at 0x2c02f3b8640>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x2c0408e0680>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x2c0408dd200>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x2c0409967a0>),\n",
       " ('spacytextblob',\n",
       "  <spacytextblob.spacytextblob.SpacyTextBlob at 0x2c03da65150>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recheck pipeline\n",
    "# Should show textblob at the end\n",
    "nlp.components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33b3ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"John love's eating apples when he works at Apple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bca773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docx = nlp(mytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67a93fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Sentiment Polarity\n",
    "docx._.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33e9a94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for subjectivity\n",
    "docx._.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38dd5df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['love'], 0.5, 0.6, None)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check assessment: list polarity/subject for the assessed token\n",
    "docx._.assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad784f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number = 5\n",
    "number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13703f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
