{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d77e40f-4dba-45f8-a0a9-f0d5af1452b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in c:\\users\\biehl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\biehl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from vaderSentiment) (2.28.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\biehl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->vaderSentiment) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\biehl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->vaderSentiment) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\biehl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->vaderSentiment) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\biehl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->vaderSentiment) (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\biehl\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install vaderSentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6408e66e-913f-4127-a91f-07a7a323a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06ab1e77-ae3c-4185-bb14-9e8ca8e3718d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1653736983.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    sentence = \"Geeks For Geeks is worse portal for \\\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#test code\n",
    "print(\"\\n1st statement :\")\n",
    "    sentence = \"Geeks For Geeks is worse portal for \\\n",
    "                the computer science engineering students.\"\n",
    " \n",
    "    # function calling\n",
    "    sentiment_scores(sentence)\n",
    " \n",
    "    print(\"\\n2nd Statement :\")\n",
    "    sentence = \"study is going on as usual\"\n",
    "    sentiment_scores(sentence)\n",
    " \n",
    "    print(\"\\n3rd Statement :\")\n",
    "    sentence = \"Barack Obama was trying to be cute\"\n",
    "    sentiment_scores(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "05ff8386-1b6a-4d03-928b-fb68a24b8c5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import SentimentIntensityAnalyzer class\n",
    "# from vaderSentiment.vaderSentiment module.\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    " \n",
    "# function to print sentiments\n",
    "# of the sentence.\n",
    "def sentiment_scores(sentence):\n",
    " \n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    " \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    # object gives a sentiment dictionary.\n",
    "    # which contains pos, neg, neu, and compound scores.\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    # decide sentiment as positive, negative and neutral\n",
    "    if sentiment_dict['pos'] - sentiment_dict['neg'] > 0:\n",
    "        return \"pos\"\n",
    "    if sentiment_dict['pos'] - sentiment_dict['neg'] < 0:\n",
    "        return \"neg\"\n",
    "\n",
    "    \n",
    "    \n",
    "#    if sentiment_dict['compound'] >= 0.5 :\n",
    "#        return \"pos\"\n",
    "# \n",
    "#    elif sentiment_dict['compound'] <= - 0.5 :\n",
    "#        return \"neg\"\n",
    "# \n",
    "#    else :\n",
    "#        return \"neu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fec42e25-1799-4c62-817d-342959562eed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare(data, annotations):\n",
    "    num_correct_neg = 0\n",
    "    num_correct_pos = 0 \n",
    "    total_neg = 0\n",
    "    total_pos = 0\n",
    "    sentence_list = []\n",
    "    for i in data['body-paragraphs']:\n",
    "        for j in i:\n",
    "            sentence_list.append(j)\n",
    "    for phrase in annotations[\"phrase-level-annotations\"]:\n",
    "        if(phrase[\"id\"] == \"title\"): # if sentiment is run on the title\n",
    "            if (sentiment_scores(data[\"title\"]) == phrase[\"polarity\"]):\n",
    "                if (phrase[\"polarity\"] == \"pos\"):\n",
    "                    num_correct_pos += 1\n",
    "                if (phrase[\"polarity\"] == \"neg\"):\n",
    "                    num_correct_neg += 1\n",
    "            if (phrase[\"polarity\"] == \"pos\"):\n",
    "                total_pos += 1\n",
    "            if (phrase[\"polarity\"] == \"neg\"):\n",
    "                total_neg += 1\n",
    "        else: # if sentiment is not run on title\n",
    "            if (len(phrase[\"id\"]) <= 3): # leave out weird IDs\n",
    "                sentence_id = int(phrase[\"id\"][1:3])\n",
    "                #print(phrase[\"id\"])\n",
    "                if (sentiment_scores(sentence_list[sentence_id]) == phrase[\"polarity\"]):\n",
    "                    if (phrase[\"polarity\"] == \"pos\"):\n",
    "                        num_correct_pos += 1\n",
    "                    if (phrase[\"polarity\"] == \"neg\"):\n",
    "                        num_correct_neg += 1\n",
    "                if (phrase[\"polarity\"] == \"pos\"):\n",
    "                    total_pos += 1\n",
    "                if (phrase[\"polarity\"] == \"neg\"):\n",
    "                    total_neg += 1\n",
    "    return num_correct_neg, num_correct_pos, total_neg, total_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "899c725f-fd87-45fe-a3c9-a947774c04a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    file_i = os.listdir(\"data/articles/201\" + str(i))\n",
    "    for file_name in file_i:\n",
    "        file = open(\"data/articles/201\" + str(i) + \"/\" + file_name, encoding=\"utf8\")\n",
    "        json_file = json.load(file)\n",
    "        file_list.append(json_file)\n",
    "        \n",
    "annotation_file_list = []\n",
    "for i in range(10):\n",
    "    file_i = os.listdir(\"data/annotations/resolved/201\" + str(i))\n",
    "    for file_name in file_i:\n",
    "        file = open(\"data/annotations/resolved/201\" + str(i) + \"/\" + file_name, encoding=\"utf8\")\n",
    "        json_file = json.load(file)\n",
    "        annotation_file_list.append(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "51c900a5-855a-4f66-814a-7312820d8f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[128], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m total \u001b[38;5;241m=\u001b[39m total_neg \u001b[38;5;241m+\u001b[39m total_pos\n\u001b[0;32m     17\u001b[0m total_correct \u001b[38;5;241m=\u001b[39m num_correct_neg \u001b[38;5;241m+\u001b[39m num_correct_pos\n\u001b[1;32m---> 18\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m (\u001b[43mtotal_accuracy\u001b[49m)\u001b[38;5;241m/\u001b[39m(total) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive accuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m via \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m samples\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(accuracy_pos, total_pos))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative accuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m via \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m samples\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(accuracy_neg, total_neg))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'total_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "num_correct_neg = 0\n",
    "num_correct_pos = 0 \n",
    "total_neg = 0\n",
    "total_pos = 0\n",
    "for i in range(len(file_list)):\n",
    "    #print(i)\n",
    "    data = file_list[i]\n",
    "    annotations = annotation_file_list[i]\n",
    "    a, b, c, d = compare(data, annotations)\n",
    "    num_correct_neg += a\n",
    "    num_correct_pos += b\n",
    "    total_neg += c\n",
    "    total_pos += d\n",
    "accuracy_neg = num_correct_neg/total_neg * 100\n",
    "accuracy_pos = num_correct_pos/total_pos * 100\n",
    "total = total_neg + total_pos\n",
    "total_correct = num_correct_neg + num_correct_pos\n",
    "accuracy = (total_correct)/(total) * 100\n",
    "print(\"positive accuracy: {}% via {} samples\".format(accuracy_pos, total_pos))\n",
    "print(\"negative accuracy: {}% via {} samples\".format(accuracy_neg, total_neg))\n",
    "print(\"accuracy: {}% via {} samples\".format(accuracy, total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "60f9d1e3-6318-42b4-870a-3f34077036f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compound < or > 0.5: \n",
    "# positive accuracy: 28.71287128712871% via 303 samples\n",
    "# negative accuracy: 21.04089219330855% via 1345 samples\n",
    "\n",
    "# compound < or > 0: \n",
    "# positive accuracy: 73.5973597359736% via 303 samples\n",
    "# negative accuracy: 47.13754646840149% via 1345 samples\n",
    "\n",
    "\n",
    "# positive - negative > or < 0: \n",
    "# positive accuracy: 55.44554455445545% via 303 samples\n",
    "# negative accuracy: 66.39405204460967% via 1345 samples\n",
    "\n",
    "# positive - negative > or < 0.05: \n",
    "# positive accuracy: 48.51485148514851% via 303 samples\n",
    "# negative accuracy: 37.32342007434944% via 1345 samples\n",
    "\n",
    "# positive - negative > or < 0.05: \n",
    "# positive accuracy: 53.135313531353134% via 303 samples\n",
    "# negative accuracy: 45.353159851301115% via 1345 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656db263-d623-4f04-9797-d17e0f9679ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CPTS421",
   "language": "python",
   "name": "cpts421"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
