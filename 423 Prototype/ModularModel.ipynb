{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9dccd1a",
   "metadata": {},
   "source": [
    "# Latent Probability Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01049288",
   "metadata": {},
   "source": [
    "If you are running this for the first time you may need to use the following commands before continuing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ba699a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1224983346.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_30416\\1224983346.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip3 install pandas==1.3.5\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip3 install pandas==1.3.5\n",
    "pip3 install spacy==3.2.0\n",
    "pip3 install spacytextblob\n",
    "python3 -m spacy download en_core_web_sm\n",
    "\n",
    "pip3 install newspaper3k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a2232",
   "metadata": {},
   "source": [
    "Spacy: Used for NLP and has the machine learning module\n",
    "    \n",
    "SpacyTextBlob: Used for the sentiment analysis\n",
    "    \n",
    "Pandas: Stores the data as a dataframe table\n",
    "    \n",
    "NewsPaper: Used for web scraping\n",
    "    \n",
    "Requests: Makes the connection to the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fae0f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "import pandas as pd\n",
    "import requests\n",
    "from newspaper import Article\n",
    "import numpy as np\n",
    "\n",
    "%run SentimentAnalysis.ipynb\n",
    "%run WebScraper.ipynb\n",
    "%run PipelineHelpers.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67afdeff",
   "metadata": {},
   "source": [
    "IMPORTANT: If you want to try re-runing after making some code changes or want to \n",
    "run a new .csv file through the code block below and the one a couple down with the\n",
    " rerun note will need to be ran again for the analysis to work correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d78c510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x1d8402ac9a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading our two pipelines\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b787c3f5",
   "metadata": {},
   "source": [
    "IMPORTANT: Insert the .csv file you want to be read below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e23034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = \"urls9.csv\"\n",
    "wordCountFilter = 500\n",
    "social_starts_with = [\"https://www.youtube.com\", \"https://youtu.be\", \"https://www.facebook.com\", \n",
    "                      \"https://twitter.com\", \"https://gettr.com/\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51cde877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun\n",
    "# Using panda to load in our .csv file\n",
    "df = pd.read_csv(csvFile) # File we are checking\n",
    "urls = df[\"Address\"].tolist() # Column name we are checking\n",
    "all_text_gathered = []\n",
    "all_articles = ''\n",
    "scentence_list = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fabe01",
   "metadata": {},
   "source": [
    "# This is the pipeline. All code is called and ran through here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ae169b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Sentiment Label</th>\n",
       "      <th>Subjectivity Score</th>\n",
       "      <th>Positive Words</th>\n",
       "      <th>Negative Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.thegatewaypundit.com/2022/05/world...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Neutral Positive</td>\n",
       "      <td>0.28</td>\n",
       "      <td>more, absolute, supporting, major, thanks, con...</td>\n",
       "      <td>absolutely, other, past, needless, single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://gettr.com/post/ptt4ta7c84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PARERROR: SocialError</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://komonews.com/news/coronavirus/if-covid...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PARERROR: Not enough words: 52 &lt; 500</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.lewrockwell.com/2018/11/no_author/...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Neutral Positive</td>\n",
       "      <td>0.41</td>\n",
       "      <td>real, most, clean, aptly, really, pure, new, e...</td>\n",
       "      <td>long, killed, hard, other, poor, less, frighte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://nation.com.pk/08-Apr-2021/russia-offer...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>Neutral Positive</td>\n",
       "      <td>0.28</td>\n",
       "      <td>full, early, particularly, more, direct, impor...</td>\n",
       "      <td>actively, mainly, foreign, military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://barrie.ctvnews.ca/cfb-borden-based-mil...</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>Neutral Negative</td>\n",
       "      <td>0.38</td>\n",
       "      <td>full, first, fine, unique, not, willingly, good</td>\n",
       "      <td>guilty, due, military, very, other, sorry, not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.reuters.com/world/us/us-army-disch...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PARERROR: Not enough words: 236 &lt; 500</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.dailysabah.com/world/europe/sweden...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PARERROR: Not enough words: 271 &lt; 500</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.military.com/daily-news/2022/11/01...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>Neutral Positive</td>\n",
       "      <td>0.46</td>\n",
       "      <td>general, most, more, best, developed, nearly, ...</td>\n",
       "      <td>limited, behind, firm, previous, approximately...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  Sentiment Score  \\\n",
       "0  https://www.thegatewaypundit.com/2022/05/world...             0.05   \n",
       "1                  https://gettr.com/post/ptt4ta7c84             0.00   \n",
       "2  https://komonews.com/news/coronavirus/if-covid...             0.00   \n",
       "3  https://www.lewrockwell.com/2018/11/no_author/...             0.10   \n",
       "4  https://nation.com.pk/08-Apr-2021/russia-offer...             0.07   \n",
       "5  https://barrie.ctvnews.ca/cfb-borden-based-mil...            -0.02   \n",
       "6  https://www.reuters.com/world/us/us-army-disch...             0.00   \n",
       "7  https://www.dailysabah.com/world/europe/sweden...             0.00   \n",
       "8  https://www.military.com/daily-news/2022/11/01...             0.07   \n",
       "\n",
       "                         Sentiment Label  Subjectivity Score  \\\n",
       "0                       Neutral Positive                0.28   \n",
       "1                  PARERROR: SocialError                0.00   \n",
       "2   PARERROR: Not enough words: 52 < 500                0.00   \n",
       "3                       Neutral Positive                0.41   \n",
       "4                       Neutral Positive                0.28   \n",
       "5                       Neutral Negative                0.38   \n",
       "6  PARERROR: Not enough words: 236 < 500                0.00   \n",
       "7  PARERROR: Not enough words: 271 < 500                0.00   \n",
       "8                       Neutral Positive                0.46   \n",
       "\n",
       "                                      Positive Words  \\\n",
       "0  more, absolute, supporting, major, thanks, con...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  real, most, clean, aptly, really, pure, new, e...   \n",
       "4  full, early, particularly, more, direct, impor...   \n",
       "5    full, first, fine, unique, not, willingly, good   \n",
       "6                                                      \n",
       "7                                                      \n",
       "8  general, most, more, best, developed, nearly, ...   \n",
       "\n",
       "                                      Negative Words  \n",
       "0          absolutely, other, past, needless, single  \n",
       "1                                                     \n",
       "2                                                     \n",
       "3  long, killed, hard, other, poor, less, frighte...  \n",
       "4                actively, mainly, foreign, military  \n",
       "5  guilty, due, military, very, other, sorry, not...  \n",
       "6                                                     \n",
       "7                                                     \n",
       "8  limited, behind, firm, previous, approximately...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loops through our URLS and scraps the data\n",
    "# Put all empty dictionaries here\n",
    "sentimentDic = {}\n",
    "    \n",
    "for count, x in enumerate(urls):\n",
    "    if(count % 10 == 0):\n",
    "        print(str(count))\n",
    "\n",
    "    url = x\n",
    "\n",
    "    # Send the URL to get scraped\n",
    "    page_text = scrapeData(x)\n",
    "    # All articles will have a long string of all the text that has been scraped\n",
    "    all_articles = all_articles + \" \" +  page_text\n",
    "    \n",
    "    # Puts the article into a list of all the sentences in the article\n",
    "    sentenceList = sentenceLevel(page_text)\n",
    "\n",
    "    # Runs sentiment analysis. Will need to make a new function and a new dictionary\n",
    "    # for each type of analysis we want to run. Will pass in the page_text, the dic, and\n",
    "    # x (the url)\n",
    "    sentimentDic = sentimentAnalysis(page_text, sentimentDic, url)\n",
    "        \n",
    "        \n",
    "        \n",
    "#print(\"The average sentiment score was: \" + str(sum(url_sent_score) / len(url_sent_score)))\n",
    "#print(\"The average subjectivity score was: \" + str(sum(url_subj_score) / len(url_subj_score)))\n",
    "\n",
    "# For each analysis we run we need to then convert that dictionary with the following method\n",
    "sentDic = dictionaryToDataFrame(sentimentDic)\n",
    "sentDic\n",
    "# Used if we want to convert it to a .csv sentDic.to_csv(\"sentiment130.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
