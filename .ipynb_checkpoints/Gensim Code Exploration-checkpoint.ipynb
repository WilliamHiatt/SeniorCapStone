{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45bcade5-0b12-4586-8b56-35e0a78feee0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\biehl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.3.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\biehl\\appdata\\roaming\\python\\python310\\site-packages (from gensim) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\biehl\\appdata\\roaming\\python\\python310\\site-packages (from gensim) (1.24.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\biehl\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (6.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\biehl\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c98bb02-b935-4209-a26f-c72e912268f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee6083f-e831-4ed2-9130-40842e97b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"Human machine interface for lab abc computer applications\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "085c291c-077c-4e1b-865e-f1e7e636481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cae2b516-451d-449c-9f6e-04a615bda943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_corpus = [\n",
    "     \n",
    "\"A male student shot and wounded two faculty members at a Denver high school on Wednesday and then fled the scene, spurring a citywide search for his whereabouts, according to city officials.\",\n",
    "\n",
    "\"The shooting at East High School was reported at about 9:50 a.m., and police and medical responders arrived on the scene “very quickly” to find two adult men with gunshot wounds, Denver Police Chief Ron Thomas said.\",\n",
    "\n",
    "\"One faculty member is in stable condition, and the other is in critical condition, he said.\",\n",
    "\n",
    "\"The student suspected in the shooting, who is under 18, was under a school safety plan in which he was patted down each day, the police chief said. During Wednesday’s search, a handgun was retrieved and several shots were fired in an office area in the front of the school, away from other students and staff, he said.\",\n",
    "\n",
    "\"The student then fled the school, and a search is underway for his whereabouts. The weapon has not been recovered, Thomas said.\",\n",
    "\n",
    "\"“We are looking for the suspect,” Mayor Michael Hancock said. “We will find that suspect, and we will hold that suspect accountable for his actions this morning in placing everyone in danger and certainly wounding the two staff members who were doing their job and trying to keep everyone safe at the time.”\",\n",
    "\n",
    "\"The mayor asked residents to look out for the student, described as an African American juvenile with an afro and wearing a hoodie with an astronaut on it. The student should be considered “armed and dangerous and willing to use the weapon, as we learned this morning,” the mayor said.\",\n",
    "\n",
    "\"In addition, another student was taken to a hospital because of an allergic reaction, the mayor said. Paramedics were already in the building for that incident when the shooting occurred and so were able to immediately treat those wounded, Hancock said.\",\n",
    "\n",
    "\"The incident is the 18th shooting this year at an elementary or secondary school in the US in which at least one person was injured or killed, according to the Gun Violence Archive, a non-profit that attempts to log every incident of gun violence in the US in real time. Just this week, one student was shot at a high school parking lot in Dallas, and in Arlington, Texas, a student was killed and another was injured in a shooting outside a high school.\",\n",
    "\n",
    "\"Wednesday also marks two years since the mass shooting at the King Soopers supermarket in Boulder, Colorado, in which 10 people were killed.\",\n",
    "\n",
    "\"East High School has about 2,500 students across 9th through 12th grades and is the largest and highest-performing comprehensive high school of all Denver Public Schools, according to the school system.\",\n",
    "\n",
    "\"The high school is located in the City Park neighborhood of the Colorado capital and is considered a Denver Historic Landmark for its architecture in the Jacobethan Revival style. The clock tower atop the school is similar in style to Philadelphia’s Independence Hall, the school website notes.\",\n",
    "\n",
    "\"Several hours after the shooting, school officials began implementing a “controlled release” of students, according to a tweet from Denver Public Schools. Students who commuted to school will be escorted to their cars, students who rode the bus will be held on campus until their bus arrives and students who were dropped off by a parent can be picked up from a separate location, the tweet says.\",\n",
    "\n",
    "\"The school will be out of session for the rest of the week following the shooting, Superintendent Alex Marrero said during a news conference. When students return and for the remainder of the school year, two armed officers would be present on campus, he said.\",\n",
    "\n",
    "\"Colorado Gov. Jared Polis issued a statement saying he was praying for the two victims’ recovery.\",\n",
    "\n",
    "\"“Our students should and must be able to attend school without fear for their safety, their parents deserve the peace of mind that their children are safe in classrooms, and teachers should be able to work safely and without harm,” he said.\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ac3777-040f-493c-8605-da78bca629ea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['student',\n",
      "  'shot',\n",
      "  'two',\n",
      "  'faculty',\n",
      "  'members',\n",
      "  'at',\n",
      "  'denver',\n",
      "  'high',\n",
      "  'school',\n",
      "  'on',\n",
      "  'wednesday',\n",
      "  'then',\n",
      "  'fled',\n",
      "  'search',\n",
      "  'his',\n",
      "  'according',\n",
      "  'city'],\n",
      " ['shooting',\n",
      "  'at',\n",
      "  'east',\n",
      "  'high',\n",
      "  'school',\n",
      "  'was',\n",
      "  'at',\n",
      "  'about',\n",
      "  'police',\n",
      "  'on',\n",
      "  'find',\n",
      "  'two',\n",
      "  'with',\n",
      "  'denver',\n",
      "  'police',\n",
      "  'chief',\n",
      "  'thomas',\n",
      "  'said.'],\n",
      " ['one',\n",
      "  'faculty',\n",
      "  'is',\n",
      "  'condition,',\n",
      "  'other',\n",
      "  'is',\n",
      "  'condition,',\n",
      "  'he',\n",
      "  'said.'],\n",
      " ['student',\n",
      "  'shooting,',\n",
      "  'who',\n",
      "  'is',\n",
      "  'under',\n",
      "  'was',\n",
      "  'under',\n",
      "  'school',\n",
      "  'which',\n",
      "  'he',\n",
      "  'was',\n",
      "  'police',\n",
      "  'chief',\n",
      "  'said.',\n",
      "  'during',\n",
      "  'was',\n",
      "  'several',\n",
      "  'were',\n",
      "  'an',\n",
      "  'school,',\n",
      "  'from',\n",
      "  'other',\n",
      "  'students',\n",
      "  'he',\n",
      "  'said.'],\n",
      " ['student',\n",
      "  'then',\n",
      "  'fled',\n",
      "  'school,',\n",
      "  'search',\n",
      "  'is',\n",
      "  'his',\n",
      "  'has',\n",
      "  'thomas',\n",
      "  'said.'],\n",
      " ['“we',\n",
      "  'are',\n",
      "  'mayor',\n",
      "  'hancock',\n",
      "  'said.',\n",
      "  '“we',\n",
      "  'will',\n",
      "  'find',\n",
      "  'that',\n",
      "  'we',\n",
      "  'will',\n",
      "  'that',\n",
      "  'his',\n",
      "  'this',\n",
      "  'everyone',\n",
      "  'two',\n",
      "  'members',\n",
      "  'who',\n",
      "  'were',\n",
      "  'their',\n",
      "  'everyone',\n",
      "  'safe',\n",
      "  'at'],\n",
      " ['mayor',\n",
      "  'out',\n",
      "  'as',\n",
      "  'an',\n",
      "  'with',\n",
      "  'an',\n",
      "  'with',\n",
      "  'an',\n",
      "  'on',\n",
      "  'student',\n",
      "  'should',\n",
      "  'be',\n",
      "  'considered',\n",
      "  'as',\n",
      "  'we',\n",
      "  'this',\n",
      "  'mayor',\n",
      "  'said.'],\n",
      " ['another',\n",
      "  'student',\n",
      "  'was',\n",
      "  'an',\n",
      "  'mayor',\n",
      "  'said.',\n",
      "  'were',\n",
      "  'that',\n",
      "  'incident',\n",
      "  'when',\n",
      "  'shooting',\n",
      "  'were',\n",
      "  'able',\n",
      "  'hancock',\n",
      "  'said.'],\n",
      " ['incident',\n",
      "  'is',\n",
      "  'shooting',\n",
      "  'this',\n",
      "  'at',\n",
      "  'an',\n",
      "  'or',\n",
      "  'school',\n",
      "  'us',\n",
      "  'which',\n",
      "  'at',\n",
      "  'one',\n",
      "  'was',\n",
      "  'injured',\n",
      "  'or',\n",
      "  'according',\n",
      "  'gun',\n",
      "  'violence',\n",
      "  'that',\n",
      "  'incident',\n",
      "  'gun',\n",
      "  'violence',\n",
      "  'us',\n",
      "  'this',\n",
      "  'one',\n",
      "  'student',\n",
      "  'was',\n",
      "  'shot',\n",
      "  'at',\n",
      "  'high',\n",
      "  'school',\n",
      "  'student',\n",
      "  'was',\n",
      "  'another',\n",
      "  'was',\n",
      "  'injured',\n",
      "  'shooting',\n",
      "  'high'],\n",
      " ['wednesday', 'two', 'shooting', 'at', 'which', 'were'],\n",
      " ['east',\n",
      "  'high',\n",
      "  'school',\n",
      "  'has',\n",
      "  'about',\n",
      "  'students',\n",
      "  'is',\n",
      "  'high',\n",
      "  'school',\n",
      "  'denver',\n",
      "  'public',\n",
      "  'according',\n",
      "  'school'],\n",
      " ['high',\n",
      "  'school',\n",
      "  'is',\n",
      "  'city',\n",
      "  'colorado',\n",
      "  'is',\n",
      "  'considered',\n",
      "  'denver',\n",
      "  'school',\n",
      "  'is',\n",
      "  'school'],\n",
      " ['several',\n",
      "  'shooting,',\n",
      "  'school',\n",
      "  'according',\n",
      "  'tweet',\n",
      "  'from',\n",
      "  'denver',\n",
      "  'public',\n",
      "  'students',\n",
      "  'who',\n",
      "  'school',\n",
      "  'will',\n",
      "  'be',\n",
      "  'their',\n",
      "  'students',\n",
      "  'who',\n",
      "  'bus',\n",
      "  'will',\n",
      "  'be',\n",
      "  'on',\n",
      "  'their',\n",
      "  'bus',\n",
      "  'students',\n",
      "  'who',\n",
      "  'were',\n",
      "  'be',\n",
      "  'from',\n",
      "  'tweet'],\n",
      " ['school',\n",
      "  'will',\n",
      "  'be',\n",
      "  'out',\n",
      "  'shooting,',\n",
      "  'during',\n",
      "  'when',\n",
      "  'students',\n",
      "  'school',\n",
      "  'two',\n",
      "  'be',\n",
      "  'on',\n",
      "  'he',\n",
      "  'said.'],\n",
      " ['colorado', 'he', 'was', 'two'],\n",
      " ['students',\n",
      "  'should',\n",
      "  'be',\n",
      "  'able',\n",
      "  'school',\n",
      "  'without',\n",
      "  'their',\n",
      "  'their',\n",
      "  'that',\n",
      "  'their',\n",
      "  'are',\n",
      "  'safe',\n",
      "  'should',\n",
      "  'be',\n",
      "  'able',\n",
      "  'without',\n",
      "  'he',\n",
      "  'said.']]\n"
     ]
    }
   ],
   "source": [
    "# Create a set of frequent words\n",
    "stoplist = set('for a of the and to in'.split(' '))\n",
    "# Lowercase each document, split it by white space and filter out stopwords\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in text_corpus]\n",
    "\n",
    "# Count word frequencies\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "# Only keep words that appear more than once\n",
    "processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "pprint.pprint(processed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "869f0c04-a8c0-475e-aaf2-cbd3556ee186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<74 unique tokens: ['according', 'at', 'city', 'denver', 'faculty']...>\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f4483ba-a425-4fd0-9549-f06f6c65ebc1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'able': 60,\n",
      " 'about': 17,\n",
      " 'according': 0,\n",
      " 'an': 32,\n",
      " 'another': 61,\n",
      " 'are': 44,\n",
      " 'as': 55,\n",
      " 'at': 1,\n",
      " 'be': 56,\n",
      " 'bus': 71,\n",
      " 'chief': 18,\n",
      " 'city': 2,\n",
      " 'colorado': 70,\n",
      " 'condition,': 27,\n",
      " 'considered': 57,\n",
      " 'denver': 3,\n",
      " 'during': 33,\n",
      " 'east': 19,\n",
      " 'everyone': 45,\n",
      " 'faculty': 4,\n",
      " 'find': 20,\n",
      " 'fled': 5,\n",
      " 'from': 34,\n",
      " 'gun': 64,\n",
      " 'hancock': 46,\n",
      " 'has': 43,\n",
      " 'he': 28,\n",
      " 'high': 6,\n",
      " 'his': 7,\n",
      " 'incident': 62,\n",
      " 'injured': 65,\n",
      " 'is': 29,\n",
      " 'mayor': 47,\n",
      " 'members': 8,\n",
      " 'on': 9,\n",
      " 'one': 30,\n",
      " 'or': 66,\n",
      " 'other': 31,\n",
      " 'out': 58,\n",
      " 'police': 21,\n",
      " 'public': 69,\n",
      " 'safe': 48,\n",
      " 'said.': 22,\n",
      " 'school': 10,\n",
      " 'school,': 35,\n",
      " 'search': 11,\n",
      " 'several': 36,\n",
      " 'shooting': 23,\n",
      " 'shooting,': 37,\n",
      " 'shot': 12,\n",
      " 'should': 59,\n",
      " 'student': 13,\n",
      " 'students': 38,\n",
      " 'that': 49,\n",
      " 'their': 50,\n",
      " 'then': 14,\n",
      " 'this': 51,\n",
      " 'thomas': 24,\n",
      " 'tweet': 72,\n",
      " 'two': 15,\n",
      " 'under': 39,\n",
      " 'us': 67,\n",
      " 'violence': 68,\n",
      " 'was': 25,\n",
      " 'we': 52,\n",
      " 'wednesday': 16,\n",
      " 'were': 40,\n",
      " 'when': 63,\n",
      " 'which': 41,\n",
      " 'who': 42,\n",
      " 'will': 53,\n",
      " 'with': 26,\n",
      " 'without': 73,\n",
      " '“we': 54}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc8ebf2f-ba0d-4ff1-9b02-0bb4f68a18dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(18, 2), (21, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"chief police chief\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5827708b-f623-4ada-ba55-87e1f3a48418",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1),\n",
      "  (1, 1),\n",
      "  (2, 1),\n",
      "  (3, 1),\n",
      "  (4, 1),\n",
      "  (5, 1),\n",
      "  (6, 1),\n",
      "  (7, 1),\n",
      "  (8, 1),\n",
      "  (9, 1),\n",
      "  (10, 1),\n",
      "  (11, 1),\n",
      "  (12, 1),\n",
      "  (13, 1),\n",
      "  (14, 1),\n",
      "  (15, 1),\n",
      "  (16, 1)],\n",
      " [(1, 2),\n",
      "  (3, 1),\n",
      "  (6, 1),\n",
      "  (9, 1),\n",
      "  (10, 1),\n",
      "  (15, 1),\n",
      "  (17, 1),\n",
      "  (18, 1),\n",
      "  (19, 1),\n",
      "  (20, 1),\n",
      "  (21, 2),\n",
      "  (22, 1),\n",
      "  (23, 1),\n",
      "  (24, 1),\n",
      "  (25, 1),\n",
      "  (26, 1)],\n",
      " [(4, 1), (22, 1), (27, 2), (28, 1), (29, 2), (30, 1), (31, 1)],\n",
      " [(10, 1),\n",
      "  (13, 1),\n",
      "  (18, 1),\n",
      "  (21, 1),\n",
      "  (22, 2),\n",
      "  (25, 3),\n",
      "  (28, 2),\n",
      "  (29, 1),\n",
      "  (31, 1),\n",
      "  (32, 1),\n",
      "  (33, 1),\n",
      "  (34, 1),\n",
      "  (35, 1),\n",
      "  (36, 1),\n",
      "  (37, 1),\n",
      "  (38, 1),\n",
      "  (39, 2),\n",
      "  (40, 1),\n",
      "  (41, 1),\n",
      "  (42, 1)],\n",
      " [(5, 1),\n",
      "  (7, 1),\n",
      "  (11, 1),\n",
      "  (13, 1),\n",
      "  (14, 1),\n",
      "  (22, 1),\n",
      "  (24, 1),\n",
      "  (29, 1),\n",
      "  (35, 1),\n",
      "  (43, 1)],\n",
      " [(1, 1),\n",
      "  (7, 1),\n",
      "  (8, 1),\n",
      "  (15, 1),\n",
      "  (20, 1),\n",
      "  (22, 1),\n",
      "  (40, 1),\n",
      "  (42, 1),\n",
      "  (44, 1),\n",
      "  (45, 2),\n",
      "  (46, 1),\n",
      "  (47, 1),\n",
      "  (48, 1),\n",
      "  (49, 2),\n",
      "  (50, 1),\n",
      "  (51, 1),\n",
      "  (52, 1),\n",
      "  (53, 2),\n",
      "  (54, 2)],\n",
      " [(9, 1),\n",
      "  (13, 1),\n",
      "  (22, 1),\n",
      "  (26, 2),\n",
      "  (32, 3),\n",
      "  (47, 2),\n",
      "  (51, 1),\n",
      "  (52, 1),\n",
      "  (55, 2),\n",
      "  (56, 1),\n",
      "  (57, 1),\n",
      "  (58, 1),\n",
      "  (59, 1)],\n",
      " [(13, 1),\n",
      "  (22, 2),\n",
      "  (23, 1),\n",
      "  (25, 1),\n",
      "  (32, 1),\n",
      "  (40, 2),\n",
      "  (46, 1),\n",
      "  (47, 1),\n",
      "  (49, 1),\n",
      "  (60, 1),\n",
      "  (61, 1),\n",
      "  (62, 1),\n",
      "  (63, 1)],\n",
      " [(0, 1),\n",
      "  (1, 3),\n",
      "  (6, 2),\n",
      "  (10, 2),\n",
      "  (12, 1),\n",
      "  (13, 2),\n",
      "  (23, 2),\n",
      "  (25, 4),\n",
      "  (29, 1),\n",
      "  (30, 2),\n",
      "  (32, 1),\n",
      "  (41, 1),\n",
      "  (49, 1),\n",
      "  (51, 2),\n",
      "  (61, 1),\n",
      "  (62, 2),\n",
      "  (64, 2),\n",
      "  (65, 2),\n",
      "  (66, 2),\n",
      "  (67, 2),\n",
      "  (68, 2)],\n",
      " [(1, 1), (15, 1), (16, 1), (23, 1), (40, 1), (41, 1)],\n",
      " [(0, 1),\n",
      "  (3, 1),\n",
      "  (6, 2),\n",
      "  (10, 3),\n",
      "  (17, 1),\n",
      "  (19, 1),\n",
      "  (29, 1),\n",
      "  (38, 1),\n",
      "  (43, 1),\n",
      "  (69, 1)],\n",
      " [(2, 1), (3, 1), (6, 1), (10, 3), (29, 3), (57, 1), (70, 1)],\n",
      " [(0, 1),\n",
      "  (3, 1),\n",
      "  (9, 1),\n",
      "  (10, 2),\n",
      "  (34, 2),\n",
      "  (36, 1),\n",
      "  (37, 1),\n",
      "  (38, 3),\n",
      "  (40, 1),\n",
      "  (42, 3),\n",
      "  (50, 2),\n",
      "  (53, 2),\n",
      "  (56, 3),\n",
      "  (69, 1),\n",
      "  (71, 2),\n",
      "  (72, 2)],\n",
      " [(9, 1),\n",
      "  (10, 2),\n",
      "  (15, 1),\n",
      "  (22, 1),\n",
      "  (28, 1),\n",
      "  (33, 1),\n",
      "  (37, 1),\n",
      "  (38, 1),\n",
      "  (53, 1),\n",
      "  (56, 2),\n",
      "  (58, 1),\n",
      "  (63, 1)],\n",
      " [(15, 1), (25, 1), (28, 1), (70, 1)],\n",
      " [(10, 1),\n",
      "  (22, 1),\n",
      "  (28, 1),\n",
      "  (38, 1),\n",
      "  (44, 1),\n",
      "  (48, 1),\n",
      "  (49, 1),\n",
      "  (50, 3),\n",
      "  (56, 2),\n",
      "  (59, 2),\n",
      "  (60, 2),\n",
      "  (73, 2)]]\n"
     ]
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "pprint.pprint(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8792c5f3-baaa-4cb1-9f12-b04520518fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 0.7644790896854718), (13, 0.6446485255033724)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "# train the model\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "\n",
    "# transform the \"system minors\" string\n",
    "words = \"student denver\".lower().split()\n",
    "print(tfidf[dictionary.doc2bow(words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a3dc7b9-b9b5-49e3-8804-ad1c13c7b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "\n",
    "index = similarities.SparseMatrixSimilarity(tfidf[bow_corpus], num_features=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b37c787f-99bc-4e32-ba97-15956d4a6fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_document = 'student police'.split()\n",
    "#query_bow = dictionary.doc2bow(query_document)\n",
    "#sims = index[tfidf[query_bow]]\n",
    "#print(list(enumerate(sims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28ceefc1-1231-4420-891a-2464dfe5f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for document_number, score in sorted(enumerate(sims), key=lambda x: x[1], reverse=True):\n",
    "#    print(document_number, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a796d1d0-6a65-4637-a4c7-e46d265e1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_open import open  # for transparently opening remote files\n",
    "\n",
    "\n",
    "class MyCorpus:\n",
    "    def __iter__(self):\n",
    "        for line in text_corpus:\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield dictionary.doc2bow(line.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9befb95-3c0b-4982-964b-f955de927c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyCorpus object at 0x000002932C93B910>\n"
     ]
    }
   ],
   "source": [
    "corpus_memory_friendly = MyCorpus()  # doesn't load the corpus into memory!\n",
    "print(corpus_memory_friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f636f905-9a65-419d-9f19-10bad3e13f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1)]\n",
      "[(1, 2), (3, 1), (6, 1), (9, 1), (10, 1), (15, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1)]\n",
      "[(4, 1), (22, 1), (27, 2), (28, 1), (29, 2), (30, 1), (31, 1)]\n",
      "[(10, 1), (13, 1), (18, 1), (21, 1), (22, 2), (25, 3), (28, 2), (29, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 2), (40, 1), (41, 1), (42, 1)]\n",
      "[(5, 1), (7, 1), (11, 1), (13, 1), (14, 1), (22, 1), (24, 1), (29, 1), (35, 1), (43, 1)]\n",
      "[(1, 1), (7, 1), (8, 1), (15, 1), (20, 1), (22, 1), (40, 1), (42, 1), (44, 1), (45, 2), (46, 1), (47, 1), (48, 1), (49, 2), (50, 1), (51, 1), (52, 1), (53, 2), (54, 2)]\n",
      "[(9, 1), (13, 1), (22, 1), (26, 2), (32, 3), (47, 2), (51, 1), (52, 1), (55, 2), (56, 1), (57, 1), (58, 1), (59, 1)]\n",
      "[(13, 1), (22, 2), (23, 1), (25, 1), (32, 1), (40, 2), (46, 1), (47, 1), (49, 1), (60, 1), (61, 1), (62, 1), (63, 1)]\n",
      "[(0, 1), (1, 3), (6, 2), (10, 2), (12, 1), (13, 2), (23, 2), (25, 4), (29, 1), (30, 2), (32, 1), (41, 1), (49, 1), (51, 2), (61, 1), (62, 2), (64, 2), (65, 2), (66, 2), (67, 2), (68, 2)]\n",
      "[(1, 1), (15, 1), (16, 1), (23, 1), (40, 1), (41, 1)]\n",
      "[(0, 1), (3, 1), (6, 2), (10, 3), (17, 1), (19, 1), (29, 1), (38, 1), (43, 1), (69, 1)]\n",
      "[(2, 1), (3, 1), (6, 1), (10, 3), (29, 3), (57, 1), (70, 1)]\n",
      "[(0, 1), (3, 1), (9, 1), (10, 2), (34, 2), (36, 1), (37, 1), (38, 3), (40, 1), (42, 3), (50, 2), (53, 2), (56, 3), (69, 1), (71, 2), (72, 2)]\n",
      "[(9, 1), (10, 2), (15, 1), (22, 1), (28, 1), (33, 1), (37, 1), (38, 1), (53, 1), (56, 2), (58, 1), (63, 1)]\n",
      "[(15, 1), (25, 1), (28, 1), (70, 1)]\n",
      "[(10, 1), (22, 1), (28, 1), (38, 1), (44, 1), (48, 1), (49, 1), (50, 3), (56, 2), (59, 2), (60, 2), (73, 2)]\n"
     ]
    }
   ],
   "source": [
    "for vector in corpus_memory_friendly:  # load one vector into memory at a time\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92529d10-cf7f-4d69-a438-44b977e38307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<61 unique tokens: ['according', 'at', 'city', 'denver', 'faculty']...>\n"
     ]
    }
   ],
   "source": [
    "# collect statistics about all tokens\n",
    "dictionary = corpora.Dictionary(line.lower().split() for line in text_corpus)\n",
    "# remove stop words and words that appear only once\n",
    "stop_ids = [\n",
    "    dictionary.token2id[stopword]\n",
    "    for stopword in stoplist\n",
    "    if stopword in dictionary.token2id\n",
    "]\n",
    "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.items() if docfreq == 1]\n",
    "dictionary.filter_tokens(stop_ids + once_ids)  # remove stop words and words that appear only once\n",
    "dictionary.compactify()  # remove gaps in id sequence after words that were removed\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9e8bff5-6315-466d-bfc3-1ecd27c0d758",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/corpus.mm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m corpus \u001b[38;5;241m=\u001b[39m [[(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m)], []]  \u001b[38;5;66;03m# make one document empty, for the heck of it\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mcorpora\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMmCorpus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/tmp/corpus.mm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\corpora\\indexedcorpus.py:122\u001b[0m, in \u001b[0;36mIndexedCorpus.serialize\u001b[1;34m(serializer, fname, corpus, id2word, index_fname, progress_cnt, labels, metadata)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m labels\n\u001b[1;32m--> 122\u001b[0m offsets \u001b[38;5;241m=\u001b[39m serializer\u001b[38;5;241m.\u001b[39msave_corpus(fname, corpus, id2word, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offsets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalled serialize on class \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m which doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support indexing!\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m serializer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    127\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\corpora\\mmcorpus.py:113\u001b[0m, in \u001b[0;36mMmCorpus.save_corpus\u001b[1;34m(fname, corpus, id2word, progress_cnt, metadata)\u001b[0m\n\u001b[0;32m    111\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstoring corpus in Matrix Market format to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, fname)\n\u001b[0;32m    112\u001b[0m num_terms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(id2word) \u001b[38;5;28;01mif\u001b[39;00m id2word \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMmWriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_corpus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_terms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_terms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_cnt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_cnt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\matutils.py:1281\u001b[0m, in \u001b[0;36mMmWriter.write_corpus\u001b[1;34m(fname, corpus, progress_cnt, index, num_terms, metadata)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_corpus\u001b[39m(fname, corpus, progress_cnt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_terms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save the corpus to disk in `Matrix Market format <https://math.nist.gov/MatrixMarket/formats.html>`_.\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \n\u001b[0;32m   1251\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1279\u001b[0m \n\u001b[0;32m   1280\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1281\u001b[0m     mw \u001b[38;5;241m=\u001b[39m \u001b[43mMmWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;66;03m# write empty headers to the file (with enough space to be overwritten later)\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m     mw\u001b[38;5;241m.\u001b[39mwrite_headers(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# will print 50 spaces followed by newline on the stats line\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\matutils.py:1172\u001b[0m, in \u001b[0;36mMmWriter.__init__\u001b[1;34m(self, fname)\u001b[0m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fname\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m fname\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.bz2\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompressed output not supported with MmWriter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfout \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# open for both reading and writing\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders_written \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\smart_open\\smart_open_lib.py:177\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transport_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     transport_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 177\u001b[0m fobj \u001b[38;5;241m=\u001b[39m \u001b[43m_shortcut_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fobj\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\smart_open\\smart_open_lib.py:363\u001b[0m, in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m    361\u001b[0m     open_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m errors\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _builtin_open(local_path, mode, buffering\u001b[38;5;241m=\u001b[39mbuffering, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopen_kwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/corpus.mm'"
     ]
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "pprint.pprint(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ba9a74-2a70-4cc1-941a-8889381ea755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CPTS421",
   "language": "python",
   "name": "cpts421"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
