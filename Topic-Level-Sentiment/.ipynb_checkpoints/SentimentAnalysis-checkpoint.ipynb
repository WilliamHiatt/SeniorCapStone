{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb0c361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "import pandas as pd\n",
    "import requests\n",
    "from newspaper import Article\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea50e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentAnalysis(text, dictionary, url):\n",
    "    if(len(dictionary) == 0):\n",
    "        dictionary = {\n",
    "            \"URL\": [],\n",
    "            \"Sentiment Score\": [],\n",
    "            \"Sentiment Label\": [],\n",
    "            \"Subjectivity Score\": [],\n",
    "            \"Positive Words\": [],\n",
    "            \"Negative Words\": [],\n",
    "            \"Text\": []\n",
    "            }\n",
    "    if(text[0:8] != \"PARERROR\"):\n",
    "        # Start the sentiment analysis now\n",
    "        dictionary[\"URL\"].append(url)\n",
    "        doc = nlp(text)\n",
    "        sentiment = doc._.blob.polarity\n",
    "        sentiment = round(sentiment,2)\n",
    "        subjectivity = doc._.blob.subjectivity\n",
    "        subjectivity = round(subjectivity,2)\n",
    "\n",
    "        # Gives positive or negative label\n",
    "        if sentiment >= 0.033 and sentiment <= 0.043:\n",
    "            sent_label = \"Neutral\"\n",
    "        elif sentiment > 0.043 and sentiment < 0.143:\n",
    "            sent_label = \"Neutral Positive\"\n",
    "        elif sentiment > 0.143:\n",
    "            sent_label = \"Positive\"\n",
    "        elif sentiment < 0.033 and sentiment > -0.062:\n",
    "            sent_label = \"Neutral Negative\"\n",
    "        elif sentiment < -0.062:\n",
    "            sent_label = \"Negative\"\n",
    "\n",
    "        dictionary[\"Sentiment Label\"].append(sent_label)\n",
    "        dictionary[\"Sentiment Score\"].append(sentiment)\n",
    "        dictionary[\"Subjectivity Score\"].append(subjectivity)\n",
    "        dictionary[\"Text\"].append(text)\n",
    "\n",
    "        positive_words = []\n",
    "        negative_words = []\n",
    "\n",
    "        for x in doc._.blob.sentiment_assessments.assessments:\n",
    "          if x[1] > 0:\n",
    "            positive_words.append(x[0][0])\n",
    "          elif x[1] < 0:\n",
    "            negative_words.append(x[0][0])\n",
    "          else:\n",
    "            pass\n",
    "\n",
    "        dictionary[\"Positive Words\"].append(', '.join(set(positive_words)))\n",
    "        dictionary[\"Negative Words\"].append(', '.join(set(negative_words)))\n",
    "    \n",
    "    else:\n",
    "        dictionary[\"URL\"].append(url)\n",
    "        dictionary[\"Sentiment Label\"].append(text)\n",
    "        dictionary[\"Sentiment Score\"].append(0.0)\n",
    "        dictionary[\"Subjectivity Score\"].append(0.0)\n",
    "        dictionary[\"Text\"].append(text)\n",
    "\n",
    "        positive_words = []\n",
    "        negative_words = []\n",
    "\n",
    "        dictionary[\"Positive Words\"].append(', '.join(set(positive_words)))\n",
    "        dictionary[\"Negative Words\"].append(', '.join(set(negative_words)))\n",
    "    \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3cf0fc",
   "metadata": {},
   "source": [
    "# Topic Level Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a58880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sentences(doc):\n",
    "#     return doc.sents\n",
    "\n",
    "# def get_sentence_list(doc):\n",
    "#     return [sent for sent in doc.sents]\n",
    "\n",
    "# #Takes a doc object from spacy and returns a tuple list of form (sentence, sentiment of sentence) for all sentences\n",
    "# def sentence_sentiment_from_doc(doc):\n",
    "#     sentences = get_sentences(doc)\n",
    "#     tuple_list = []\n",
    "#     for sentence in sentences:\n",
    "#         sent_doc = nlp(sentence.text)\n",
    "#         tuple_list.append((sentence.text,sent_doc._.blob.polarity))\n",
    "#     return tuple_list\n",
    "\n",
    "# #takes in a single topic word, the word's weight, and the doc, and returns sentiment of that word within the doc\n",
    "# def sentence_level_sentiment_of_word(word, weight, doc):\n",
    "#     sentence_sentiment_list = sentence_sentiment_from_doc(doc)\n",
    "#     sentiment_total = 0\n",
    "    \n",
    "#     for (sentence, sentiment) in sentence_sentiment_list:\n",
    "#              if sentence.find(word) != -1:\n",
    "#                     #print(name,sentence)\n",
    "#                     sentiment_total += sentiment\n",
    "#     return sentiment_total\n",
    "\n",
    "# def topic_level_sentiment(ldamodel):\n",
    "#     my_dict = {'Topic_' + str(i): [token for token, score in ldamodel.show_topic(i, topn=10)] for i in range(0, ldamodel.num_topics)}\n",
    "    \n",
    "#     return my_dict\n",
    "\n",
    "#returns a dictionary of all topics, with all their associated topic words in the form {Topic: [words]}\n",
    "def create_topic_words_dict(ldamodel):\n",
    "    my_dict = {'Topic_' + str(i): [token for token, score in ldamodel.show_topic(i, topn=10)] for i in range(0, ldamodel.num_topics)}\n",
    "    \n",
    "    return my_dict\n",
    "\n",
    "#returns all sentences in a document as a list\n",
    "def get_sentences(doc):\n",
    "    return doc.sents\n",
    "\n",
    "#Takes a doc object from spacy and returns a tuple list of form (sentence, sentiment of sentence) for all sentences\n",
    "def sentence_sentiment_from_doc(doc):\n",
    "    sentences = get_sentences(doc)\n",
    "    tuple_list = []\n",
    "    for sentence in sentences:\n",
    "        sent_doc = nlp(sentence.text)\n",
    "        tuple_list.append((sentence.text,sent_doc._.blob.polarity)) #list of tuples of form [(text, sentiment)]\n",
    "    return tuple_list\n",
    "\n",
    "#Returns an average sentiment score of all topics for a single document\n",
    "def sentence_sentiment_on_topics(doc, topic_list, df_topics):\n",
    "    sentence_sentiment_list = sentence_sentiment_from_doc(doc) #get all sentences and their sentiment\n",
    "    score_list = []\n",
    "    return_dict = {}\n",
    "    \n",
    "    for key in topic_list: #for every topic\n",
    "        for topic in df_topics: # every topic within our current article\n",
    "            print(key[-1])\n",
    "            print(topic[0])\n",
    "            print(type(key[-1]))\n",
    "            print(type(topic[0]))\n",
    "            if int(key[-1]) == topic[0]: # Only does sentiment on topics that are part of the related topics\n",
    "                print(\"HERE\")\n",
    "                for word in topic_list[key]: #for every word in that topic\n",
    "                    for sentence, sentiment in sentence_sentiment_list:\n",
    "                         if sentence.find(word) != -1: #if the word is in that sentence we add the sentiment value\n",
    "                                score_list.append(sentiment)\n",
    "                if not score_list:\n",
    "                    return_dict[key] = 0\n",
    "                else:\n",
    "                    return_dict[key] = sum(score_list) / len(score_list) #average of all sentence sentiments for topic\n",
    "    \n",
    "    return return_dict\n",
    "\n",
    "def topic_sentence_sentiment_analysis(df, LDA_model, corpus):\n",
    "    #cleaneddf = drop_failed_webscraping_rows(df)\n",
    "    #LDA_model, corpus = create_lda_model(cleaneddf, 20, 5, 5)\n",
    "\n",
    "    topicSentDic = {}\n",
    "    for x in range(len(df[\"URL\"])): #for every article\n",
    "        page_text = df.iloc[x][\"Text\"]\n",
    "        df_topics = df.iloc[x][\"Topics\"]\n",
    "        tempdoc = nlp(page_text) #gather page text and transform into doc object\n",
    "        topic_list = create_topic_words_dict(LDA_model) #list of topics and their words\n",
    "        temp = sentence_sentiment_on_topics(tempdoc,topic_list, df_topics) #dictionary of all topics and their average sentiment for the article\n",
    "        topicSentDic[df.iloc[x][\"URL\"]] = temp #append sentiment dict\n",
    "    \n",
    "    return topicSentDic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
