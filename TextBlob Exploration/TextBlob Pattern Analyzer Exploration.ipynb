{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d33596b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\gabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.17.1)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\gabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\gabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\gabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\gabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\gabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ba57bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.taggers import PatternTagger\n",
    "from textblob.sentiments import PatternAnalyzer\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a1be300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify the sentiment value into positive, neutral, and negative\n",
    "analyzer = PatternAnalyzer() #POLARITY AND SUBJECTIVITY ANALYZER\n",
    "tagger = PatternTagger() #PART OF SPEECH TAGGER\n",
    "\n",
    "\n",
    "def pattern_analyzer_classify(sentence):\n",
    "    score = analyzer.analyze(sentence)\n",
    "    if score[0] > 0.1:\n",
    "        return \"pos\"\n",
    "    elif score[0] < 0.1:\n",
    "        return \"neg\"\n",
    "    else:\n",
    "        return \"neu\"\n",
    "    \n",
    "#compare results of data using pattern analyzer compared to correct annotations\n",
    "def pattern_analyzer_compare(data, annotations): #compares how many we correctly classify\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    sentence_list = []\n",
    "    for i in data['body-paragraphs']:\n",
    "        for j in i:\n",
    "            sentence_list.append(j)\n",
    "    for phrase in annotations[\"phrase-level-annotations\"]:\n",
    "        if(phrase[\"id\"] == \"title\"):#line below is where we input our model\n",
    "            if (pattern_analyzer_classify(data[\"title\"]) == phrase[\"polarity\"]):\n",
    "                num_correct += 1\n",
    "            total += 1\n",
    "        else:\n",
    "            sentence_id = int(phrase[\"id\"][1:])#input model below here too\n",
    "            if (pattern_analyzer_classify(sentence_list[sentence_id]) == phrase[\"polarity\"]):\n",
    "                num_correct += 1\n",
    "            total += 1\n",
    "    return total, num_correct\n",
    "\n",
    "###TAGGER FUNCTIONS\n",
    "\n",
    "def pattern_tag(sentence):\n",
    "    blob = TextBlob(sentence, pos_tagger=tagger)\n",
    "    return blob.pos_tags\n",
    "\n",
    "def find_proper_names(pos_tags):\n",
    "    tuple_list = []\n",
    "    for pos_tuple in pos_tags:\n",
    "        #find the NNP tagged words and return those tuples as a new list\n",
    "        if pos_tuple[1] == 'NNP':\n",
    "            tuple_list.append(pos_tuple)\n",
    "    return tuple_list\n",
    "\n",
    "def find_full_proper_names_list(pos_tags): #only accounts for first+last names\n",
    "    name_list = []\n",
    "    prev_tuple = (\"___\",'___')\n",
    "    for pos_tuple in pos_tags:\n",
    "        #find the NNP tagged words and return those tuples as a new list\n",
    "        if pos_tuple[1] == 'NNP':\n",
    "            if prev_tuple[1] == 'NNP':\n",
    "                name_list.remove(prev_tuple[0])\n",
    "                name_list.append(prev_tuple[0] + \" \" + pos_tuple[0])\n",
    "            else:\n",
    "                name_list.append(pos_tuple[0])\n",
    "        prev_tuple = pos_tuple\n",
    "    return name_list\n",
    "\n",
    "#create another function of find_proper_names that combines full names\n",
    "#basically check if two NNP words are next to each  other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d90e993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern analyzer test1:\n",
      "Sentiment(polarity=-0.8, subjectivity=0.9)\n",
      "-0.8\n",
      "[('I', 'PRP'), ('hate', 'VBP'), ('the', 'DT'), ('things', 'NNS'), ('that', 'IN'), ('Trump', 'NNP'), ('has', 'VBZ'), ('done', 'VBN'), ('over', 'IN'), ('the', 'DT'), ('years', 'NNS')]\n",
      "\n",
      "\n",
      "[('Trump', 'NNP')]\n",
      "['Trump']\n",
      "\n",
      "\n",
      "[('What', 'WP'), ('’', 'NN'), ('s', 'PRP'), ('Worse', 'JJR'), ('for', 'IN'), ('Donald', 'NNP'), ('Trump', 'NNP'), ('Than', 'IN'), ('Getting', 'VBG'), ('Indicted', 'VBN')]\n",
      "\n",
      "\n",
      "[('Donald', 'NNP'), ('Trump', 'NNP')]\n",
      "['Donald Trump']\n",
      "\n",
      "\n",
      "[('A', 'DT'), ('fierce', 'JJ'), ('debate', 'NN'), ('between', 'IN'), ('Obama', 'NNP'), ('and', 'CC'), ('Donald', 'NNP'), ('Trump', 'NNP'), ('ensued', 'VBD'), ('on', 'IN'), ('tuesday', 'NN')]\n",
      "['Obama', 'Donald Trump']\n"
     ]
    }
   ],
   "source": [
    "###EXPLORATION START\n",
    "pattern_analyzer1 = PatternAnalyzer()\n",
    "\n",
    "test_sent1 = \"I hate the things that Trump has done over the years.\"\n",
    "test_sent2 = \"In an Epic Battle of Tanks, Russia Was Routed, Repeating Earlier Mistakes\"\n",
    "test_sent3 = \"Ukraine war live updates: Russian mercenary boss says ‘fierce resistance’ seen in Bakhmut; Kyiv says its fighters are under ‘insane pressure’\"\n",
    "test_sent4 = \"What’s Worse for Donald Trump Than Getting Indicted?\"\n",
    "test_sent5 = \"A fierce debate between Obama and Donald Trump ensued on tuesday.\"\n",
    "#pattern analyzer returns a tuple of polarity, subjectivity\n",
    "#and if you set it to true also a list of assessments made on \n",
    "#individual words\n",
    "\n",
    "print(\"Pattern analyzer test1:\")\n",
    "print(pattern_analyzer1.analyze(test_sent1))\n",
    "# test_analyzing2 = pattern_analyzer1.analyze(test_sent2,keep_assessments = True)\n",
    "# print(test_analyzing2)\n",
    "# print(\"Pattern test3: \" + pattern_analyzer_classify(test_sent3))\n",
    "# print(pattern_analyzer1.analyze(test_sent3))\n",
    "\n",
    "print(pattern_analyzer1.analyze(test_sent1)[0])\n",
    "\n",
    "\n",
    "#TAGGING EXPLORATION\n",
    "tags1 = pattern_tag(test_sent1)\n",
    "print(tags1)\n",
    "print(\"\\n\")\n",
    "print(find_proper_names(tags1))\n",
    "print(find_full_proper_names_list(tags1))\n",
    "print(\"\\n\")\n",
    "tags4 = pattern_tag(test_sent4)\n",
    "print(tags4)\n",
    "print(\"\\n\")\n",
    "print(find_proper_names(tags4))\n",
    "print(find_full_proper_names_list(tags4))\n",
    "print(\"\\n\")\n",
    "tags5 = pattern_tag(test_sent5)\n",
    "print(tags5)\n",
    "print(find_full_proper_names_list(tags5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c66fa4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern sentiment on BASIL correct: 1130.000 , BASIL total: 1726.000\n",
      "Pattern sentiment on BASIL ACCURACY: 0.6547\n"
     ]
    }
   ],
   "source": [
    "file_list = []\n",
    "\n",
    "#open BASIL dataset and gather the articles w/o scores\n",
    "for i in range(10):\n",
    "    file_i = os.listdir(\"BASILdata/articles/201\" + str(i))\n",
    "    for file_name in file_i:\n",
    "        file = open(\"BASILdata/articles/201\" + str(i) + \"/\" + file_name, encoding=\"utf8\")\n",
    "        json_file = json.load(file)\n",
    "        file_list.append(json_file)\n",
    "        \n",
    "annotation_file_list = []\n",
    "\n",
    "#open BASIL dataset and gather annotations for articles\n",
    "for i in range(10):\n",
    "    file_i = os.listdir(\"BASILdata/annotations/201\" + str(i))\n",
    "    for file_name in file_i:\n",
    "        file = open(\"BASILdata/annotations/201\" + str(i) + \"/\" + file_name, encoding=\"utf8\")\n",
    "        json_file = json.load(file)\n",
    "        annotation_file_list.append(json_file)\n",
    "\n",
    "total_correct = 0\n",
    "total = 0\n",
    "\n",
    "#compare correct annotations to the results from our model\n",
    "for i in range(len(file_list)):\n",
    "    data = file_list[i]\n",
    "    annotations = annotation_file_list[i]\n",
    "    a, b = pattern_analyzer_compare(data, annotations)\n",
    "    total += a\n",
    "    total_correct += b\n",
    "    \n",
    "accuracy = total_correct/total\n",
    "print(\"Pattern sentiment on BASIL correct: %.3f , BASIL total: %.3f\" %(total_correct, total))\n",
    "print(\"Pattern sentiment on BASIL ACCURACY: %.4f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2244f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
