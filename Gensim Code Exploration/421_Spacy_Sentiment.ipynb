{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc3c193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.5.2-cp39-cp39-win_amd64.whl (12.2 MB)\n",
      "     --------------------------------------- 12.2/12.2 MB 31.2 MB/s eta 0:00:00\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.6-cp39-cp39-win_amd64.whl (482 kB)\n",
      "     ---------------------------------------- 482.8/482.8 kB ? eta 0:00:00\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting pathy>=0.10.0\n",
      "  Using cached pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Downloading thinc-8.1.9-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 47.3 MB/s eta 0:00:00\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Using cached typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy) (65.6.3)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp39-cp39-win_amd64.whl (18 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Using cached wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.7-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 35.0 MB/s eta 0:00:00\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp39-cp39-win_amd64.whl (96 kB)\n",
      "     ---------------------------------------- 96.8/96.8 kB 5.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp39-cp39-win_amd64.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 40.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, pydantic, murmurhash, langcodes, catalogue, blis, typer, srsly, preshed, pathy, confection, thinc, spacy\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.0.4 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.7 spacy-3.5.2 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.9 typer-0.7.0 wasabi-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8c2a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.0-cp311-cp311-win_amd64.whl (11.2 MB)\n",
      "                                              0.0/11.2 MB ? eta -:--:--\n",
      "                                              0.0/11.2 MB ? eta -:--:--\n",
      "                                             0.0/11.2 MB 325.1 kB/s eta 0:00:35\n",
      "                                             0.0/11.2 MB 325.1 kB/s eta 0:00:35\n",
      "                                             0.1/11.2 MB 363.1 kB/s eta 0:00:31\n",
      "                                             0.1/11.2 MB 554.9 kB/s eta 0:00:20\n",
      "                                             0.2/11.2 MB 655.4 kB/s eta 0:00:17\n",
      "                                             0.3/11.2 MB 896.4 kB/s eta 0:00:13\n",
      "     -                                        0.4/11.2 MB 1.0 MB/s eta 0:00:11\n",
      "     -                                        0.5/11.2 MB 1.3 MB/s eta 0:00:09\n",
      "     --                                       0.6/11.2 MB 1.4 MB/s eta 0:00:08\n",
      "     --                                       0.7/11.2 MB 1.5 MB/s eta 0:00:07\n",
      "     --                                       0.8/11.2 MB 1.5 MB/s eta 0:00:07\n",
      "     ---                                      1.1/11.2 MB 1.8 MB/s eta 0:00:06\n",
      "     ----                                     1.3/11.2 MB 2.1 MB/s eta 0:00:05\n",
      "     ------                                   1.8/11.2 MB 2.6 MB/s eta 0:00:04\n",
      "     --------                                 2.5/11.2 MB 3.5 MB/s eta 0:00:03\n",
      "     -----------                              3.2/11.2 MB 4.2 MB/s eta 0:00:02\n",
      "     ----------------                         4.7/11.2 MB 5.7 MB/s eta 0:00:02\n",
      "     ---------------------                    6.1/11.2 MB 6.9 MB/s eta 0:00:01\n",
      "     ----------------------------             8.0/11.2 MB 8.7 MB/s eta 0:00:01\n",
      "     -----------------------------------     10.2/11.2 MB 10.5 MB/s eta 0:00:01\n",
      "     --------------------------------------- 11.2/11.2 MB 23.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\biehl\\anaconda3\\envs\\cpts421\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "                                              0.0/502.3 kB ? eta -:--:--\n",
      "     ------------------------------------- 502.3/502.3 kB 32.8 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "                                              0.0/341.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 341.8/341.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\biehl\\anaconda3\\envs\\cpts421\\lib\\site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\biehl\\anaconda3\\envs\\cpts421\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.0.0 pytz-2023.3 tzdata-2023.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24a3a313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacytextblobNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached spacytextblob-4.0.0-py3-none-any.whl (4.5 kB)\n",
      "Requirement already satisfied: spacy<4.0,>=3.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacytextblob) (3.5.2)\n",
      "Collecting textblob<0.16.0,>=0.15.3\n",
      "  Using cached textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (1.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (1.0.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (2.4.6)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (0.10.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (3.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (8.1.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (2.0.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (65.6.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (5.2.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (22.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (2.11.3)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (0.7.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (1.10.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (4.64.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (1.1.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<4.0,>=3.0->spacytextblob) (2.28.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from textblob<0.16.0,>=0.15.3->spacytextblob) (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob<0.16.0,>=0.15.3->spacytextblob) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob<0.16.0,>=0.15.3->spacytextblob) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob<0.16.0,>=0.15.3->spacytextblob) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<4.0,>=3.0->spacytextblob) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.0->spacytextblob) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.0->spacytextblob) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.0->spacytextblob) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0,>=3.0->spacytextblob) (2.0.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<4.0,>=3.0->spacytextblob) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<4.0,>=3.0->spacytextblob) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<4.0,>=3.0->spacytextblob) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from jinja2->spacy<4.0,>=3.0->spacytextblob) (2.0.1)\n",
      "Installing collected packages: textblob, spacytextblob\n",
      "Successfully installed spacytextblob-4.0.0 textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "pip install spacytextblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37d84662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     --------------------------------------- 12.8/12.8 MB 17.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.11.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.6.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (22.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.5.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6098f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Using cached bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=e76573f216eecc7567049b45381fbceed723a8595c853f002e864ef3549c3dd4\n",
      "  Stored in directory: c:\\users\\biehl\\appdata\\local\\pip\\cache\\wheels\\8b\\ac\\c5\\cb646ab01df6f353a9994b1c97dffb94f9b12013d64c162c58\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Requirement already satisfied: gensim in c:\\users\\biehl\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from gensim) (1.9.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\biehl\\anaconda3\\lib\\site-packages (from gensim) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f306d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf6adcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x19201604300>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading our two pipelines\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "config = {\"punct_chars\": [\".\", \"?\", \"!\", \"。\"]}\n",
    "nlp.add_pipe('sentencizer', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1370ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using panda to load in our .csv file\n",
    "df = pd.read_csv(\"urls.csv\") # File we are checking\n",
    "urls = df[\"Address\"].tolist() # Column name we are checking\n",
    "url_sent_score = []\n",
    "url_sent_label = []\n",
    "url_subj_score = []\n",
    "url_subj_label = []\n",
    "total_pos = []\n",
    "total_neg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e4fcca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_named_entities(doc):\n",
    "    ent_list = []\n",
    "    for ent in doc.ents:\n",
    "        ent_list.append((ent.text,ent.label_))\n",
    "    return ent_list\n",
    "\n",
    "def get_sentences(doc):\n",
    "    return doc.sents\n",
    "\n",
    "def get_sentence_list(doc):\n",
    "    return [sent for sent in doc.sents]\n",
    "\n",
    "def sentence_sentiment_from_doc(doc):\n",
    "    sentences = get_sentences(doc)\n",
    "    tuple_list = []\n",
    "    for sentence in sentences:\n",
    "        sent_doc = nlp(sentence.text)\n",
    "        tuple_list.append((sentence,sent_doc._.blob.polarity))\n",
    "    return tuple_list\n",
    "\n",
    "#def sentence_sentiment_on_named_entities(doc):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63917c2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter test spot\n",
      "\n",
      "[(11 minutes of aerobics daily lowers disease risk, study says | cnn\n",
      " \n",
      " \n",
      "11 minutes of daily exercise could have a positive impact on your health, large study shows\n",
      "\t\t\tby kristen rogers, cnn\n",
      "\t\t\n",
      "updated\n",
      "6:45 am est, wed march 1, 2023\n",
      "link copied!\n",
      " \n",
      ", 0.12378246753246752), (this may look silly, but a new study reveals its benefits to your daily routine\n",
      "02:34\n",
      " - source:\n",
      "cnn\n",
      "your health\n",
      "16 videos\n",
      "this may look silly, but a new study reveals its benefits to your daily routine\n",
      "02:34\n",
      "now playing\n",
      " - source:\n",
      ", -0.12121212121212122), (cnn\n",
      "if you have allergies, you may want to avoid this type of medication\n",
      "02:18\n",
      "now playing\n",
      " - source:\n",
      "cnn\n",
      "doctor explains new over-the-counter medicine that's a 'complete antidote to opioids'\n",
      "01:59\n",
      "now playing\n",
      " - source:\n",
      "cnn\n",
      "maternity wards across the us are closing because of this issue\n",
      "02:31\n",
      "now playing\n",
      " - source:\n",
      "cnn\n",
      "nearly 40% of dementia cases can be prevented with one small health change\n",
      "02:13\n",
      "now playing\n",
      " - source:\n",
      "cnn\n",
      "this type of exercise might be better for your brain than biking or jogging\n",
      "02:03\n",
      "now playing\n",
      " - source:\n",
      "cnn\n",
      "toddler suffers from disease that makes him 'human time bomb'\n",
      "05:46\n",
      "now playing\n",
      " - source:\n",
      "cnn\n",
      "young model becomes double-amputee after covid\n",
      "02:32\n",
      "now playing\n",
      " - source:\n",
      "cnn\n",
      "sleep specialist has 4 tips to help stop snoring\n",
      "01:43\n",
      "now playing\n",
      " - source:\n",
      "cnn\n",
      "is it forgetfulness or dementia?, 0.010795454545454556), (this is how your doctor finds out\n",
      "02:53\n",
      "now playing\n",
      " - source:\n",
      "cnn\n",
      "harvard psychiatrist says this is the secret to happiness\n",
      "02:33\n",
      "now playing\n",
      " - source:\n",
      "cnn\n",
      "this 95-second video will help you build a habit for good\n",
      "01:35\n",
      "now playing\n",
      " - source:\n",
      "cnn\n",
      "leading us doctor says he won't get treatment if he gets cancer after 75\n",
      "01:35\n",
      "now playing\n",
      " - source:\n",
      "cnn\n",
      "what is mpox?, 0.3333333333333333), (dr. gupta explains how this rare virus spreads\n",
      "02:54\n",
      "now playing\n",
      " - source:\n",
      "cnn\n",
      "cnn gets rare inside look at nfl protocol that saved damar hamlin's life\n",
      "05:56\n",
      "now playing\n",
      " - source:\n",
      "cnn\n",
      "doctor explains what rsv symptoms to look for\n",
      "01:45\n",
      "now playing\n",
      " - source:\n",
      "cnn\n",
      "see more videos\n",
      "sign up for cnn’s fitness, but better newsletter series., 0.4), (our seven-part guide up will help you ease into a healthy routine, backed by experts.\n",
      ", 0.5), (cnn\n",
      " — \n",
      "when you can’t fit your entire workout into a busy day, do you think there’s no point in doing anything at all?, 0.16666666666666666), (you should rethink that mindset., 0.0), (just 11 minutes of moderate-to-vigorous intensity aerobic activity per day could lower your risk of cancer, cardiovascular disease or premature death, a large new study has found. \n",
      ", 0.17532467532467533), (aerobic activities include walking, dancing, running, jogging, cycling and swimming., 0.0), (you can gauge the intensity level of an activity by your heart rate and how hard you’re breathing as you move., -0.2916666666666667), (generally, being able to talk but not sing during an activity would make it moderate intensity., 0.18333333333333335), (vigorous intensity is marked by the inability to carry on a conversation. \n",
      ", 0.1), (higher levels of physical activity have been associated with lower rates of premature death and chronic disease, according to past research., 0.0), (but how the risk levels for these outcomes are affected by the amount of exercise someone gets has been more difficult to determine., 0.0), (to explore this impact, scientists largely from the university of cambridge in the united kingdom looked at data from 196 studies, amounting to more than 30 million adult participants who were followed for 10 years on average., 0.16607142857142856), (the results of this latest study were published tuesday in the british journal of sports medicine. \n",
      ", 0.25), (adding 11 minutes of exercise to your day could lower your risk of chronic disease and death, new research has found.\n",
      ", 0.13636363636363635), (li zhongfei/adobe stock\n",
      "the study mainly focused on participants who had done the minimum recommended amount of 150 minutes of exercise per week, or 22 minutes per day., 0.16666666666666666), (compared with inactive participants, adults who had done 150 minutes of moderate-to-vigorous aerobic physical activity per week had a 31% lower risk of dying from any cause, a 29% lower risk of dying from cardiovascular disease and a 15% lower risk of dying from cancer. \n",
      ", 0.0), (the same amount of exercise was linked with a 27% lower risk of developing cardiovascular disease and 12% lower risk when it came to cancer.\n",
      ", 0.0), (“this is a compelling systematic review of existing research,” said cnn medical analyst dr. leana wen, an emergency physician and public health professor at george washington university, who wasn’t involved in the research., 0.09999999999999999), (“we already knew that there was a strong correlation between increased physical activity and reduced risk for cardiovascular disease, cancer and premature death., 0.21666666666666665), (this research confirms it, and furthermore states that a smaller amount than the 150 minutes of recommended exercise a week can help.”\n",
      "even people who got just half the minimum recommended amount of physical activity benefited., -0.05555555555555555), (accumulating 75 minutes of moderate-intensity activity per week — about 11 minutes of activity per day — was associated with a 23% lower risk of early death., 0.1), (getting active for 75 minutes on a weekly basis was also enough to reduce the risk of developing cardiovascular disease by 17% and cancer by 7%. \n",
      ", -0.06666666666666667), (adobe stock\n",
      "irregular sleep may be harmful to your heart, study finds\n",
      "beyond 150 minutes per week, any additional benefits were smaller. \n",
      ", 0.0), (“if you are someone who finds the idea of 150 minutes of moderate-intensity physical activity a week a bit daunting, then our findings should be good news,” said study author dr. soren brage, group leader of the physical activity epidemiology group in the medical research council epidemiology unit at the university of cambridge, in a news release., 0.175), (“this is also a good starting position — if you find that 75 minutes a week is manageable, then you could try stepping it up gradually to the full recommended amount.” \n",
      ", 0.3499999999999999), (the authors’ findings affirm the world health organization’s position that doing some physical activity is better than doing none, even if you don’t get the recommended amounts of exercise.\n",
      ", 0.25), (“one in 10 premature deaths could have been prevented if everyone achieved even half the recommended level of physical activity,” the authors wrote in the study., -0.08333333333333333), (additionally, “10.9% and 5.2% of all incident cases of cvd (cardiovascular disease) and cancer would have been prevented.” \n",
      ", 0.0), (important note: if you experience pain while exercising, stop immediately., 0.4), (check with your doctor before beginning any new exercise program.\n",
      ", 0.13636363636363635), (a little exercise every day \n",
      "the authors didn’t have details on the specific types of physical activity the participants did., -0.0625), (but some experts do have thoughts on how physical activity could reduce risk for chronic diseases and premature death. \n",
      ", 0.0), (“there are many potential mechanisms including the improvement and maintenance of body composition, insulin resistance and physical function because of a wide variety of favorable influences of aerobic activity,” said haruki momma, an associate professor of medicine and science in sports and exercise at tohoku university in japan., 0.1), (momma wasn’t involved in the research. \n",
      ", 0.0), (benefits could also include improvement to immune function, lung and heart health, inflammation levels, hypertension, cholesterol, and amount of body fat, said eleanor watts, a postdoctoral fellow in the division of cancer epidemiology and genetics at the national cancer institute., 0.0), (watts wasn’t involved in the research. \n",
      ", 0.0), (photo illustration/leah abucayan\n",
      "get moving faster with cardio: how to reboot your workout routine\n",
      "“these translate into lower risk of getting chronic diseases,” said peter katzmarzyk, associate executive director for population and public health sciences at pennington biomedical research center in baton rouge, louisiana., -0.05), (katzmarzyk wasn’t involved in the research. \n",
      ", 0.0), (the fact that participants who did only half the minimum recommended amount of exercise still experienced benefits doesn’t mean people shouldn’t aim for more exercise, but rather that “perfect shouldn’t be the enemy of the good,” wen said., 0.36011904761904756), (“some is better than none.” \n",
      ", 0.5), (to get up to 150 minutes of physical activity per week, find activities you enjoy, wen said., 0.2), (“you are far more likely to engage in something you love doing than something you have to make yourself do.” \n",
      ", 0.275), (and when it comes to how you fit in your exercise, you can think outside the box. \n",
      ", 0.2), (“moderate activity doesn’t have to involve what we normally think of (as) exercise, such as sports or running,” said study coauthor leandro garcia, a lecturer in the school of medicine, dentistry and biomedical sciences at queen’s university belfast, in a news release., 0.049999999999999996), (“sometimes, replacing some habits is all that is needed. \n",
      ", 0.0), (“for example, try to walk or cycle to your work or study place instead of using a car, or engage in active play with your kids or grand kids., 0.18333333333333335), (doing activities that you enjoy and that are easy to include in your weekly routine is an excellent way to become more active.” \n",
      " \n",
      ", 0.44000000000000006), (related, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "#https://pypi.org/project/spacytextblob/\n",
    "for count, x in enumerate(urls):\n",
    "    try:\n",
    "        url = x\n",
    "\n",
    "        headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36'}\n",
    "        res = requests.get(url,headers=headers)\n",
    "        html_page = res.text\n",
    "\n",
    "        soup = BeautifulSoup(html_page, 'html.parser')\n",
    "        for script in soup([\"script\", \"style\",\"meta\",\"label\",\"header\",\"footer\"]):\n",
    "            script.decompose()\n",
    "        page_text = (soup.get_text()).lower()\n",
    "        page_text = page_text.strip().replace(\"  \",\"\")\n",
    "        page_text = \"\".join([s for s in page_text.splitlines(True) if s.strip(\"\\r\\n\")])\n",
    "\n",
    "        # Start the sentiment analysis now\n",
    "        doc = nlp(page_text)\n",
    "        sentiment = doc._.blob.polarity\n",
    "        sentiment = round(sentiment,2)\n",
    "        subjectivity = doc._.blob.subjectivity\n",
    "        subjectivity = round(subjectivity,2)\n",
    "        \n",
    "        #exploration of single topic modeling and sentiment\n",
    "        #print(doc._.blob.sentiment_assessments)\n",
    "        #print([(w.text, w.pos_) for w in doc])\n",
    "        \n",
    "        if count / 1 == 1:\n",
    "            print(\"enter test spot\\n\")\n",
    "            ent_list = get_named_entities(doc)\n",
    "            #print(ent_list)\n",
    "            sentence_sentiment_list = sentence_sentiment_from_doc(doc)\n",
    "            print(sentence_sentiment_list)\n",
    "            break\n",
    "            \n",
    "        #print(\"\\n\")\n",
    "\n",
    "        # Gives positive or negative label\n",
    "        if sentiment >= -0.033 and sentiment <= 0.043:\n",
    "            sent_label = \"Neutral\"\n",
    "        elif sentiment > 0.043 and sentiment < 0.143:\n",
    "            sent_label = \"Neutral Positive\"\n",
    "        elif sentiment > 0.143:\n",
    "            sent_label = \"Positive\"\n",
    "        elif sentiment < -0.033 and sentiment > -0.062:\n",
    "            sent_label = \"Neutral Negative\"\n",
    "        elif sentiment < -0.062:\n",
    "            sent_label = \"Negative\"\n",
    "\n",
    "        url_sent_label.append(sent_label)\n",
    "        url_sent_score.append(sentiment)\n",
    "        url_subj_score.append(subjectivity)\n",
    "\n",
    "        positive_words = []\n",
    "        negative_words = []\n",
    "\n",
    "        for x in doc._.blob.sentiment_assessments.assessments:\n",
    "          if x[1] > 0:\n",
    "            positive_words.append(x[0][0])\n",
    "          elif x[1] < 0:\n",
    "            negative_words.append(x[0][0])\n",
    "          else:\n",
    "            pass\n",
    "\n",
    "        total_pos.append(', '.join(set(positive_words)))\n",
    "        total_neg.append(', '.join(set(negative_words)))\n",
    "    except:\n",
    "        url_sent_label.append(\"Error\")\n",
    "        url_sent_score.append(0.0)\n",
    "        url_subj_score.append(0.0)\n",
    "\n",
    "        positive_words = []\n",
    "        negative_words = []\n",
    "\n",
    "        total_pos.append(', '.join(set(positive_words)))\n",
    "        total_neg.append(', '.join(set(negative_words)))\n",
    "\n",
    "# print(\"The average sentiment score was: \" + str(sum(url_sent_score) / len(url_sent_score)))\n",
    "# print(\"The average subjectivity score was: \" + str(sum(url_subj_score) / len(url_subj_score)))\n",
    "\n",
    "# df[\"Sentiment Score\"] = url_sent_score\n",
    "# df[\"Sentiment Label\"] = url_sent_label\n",
    "# df[\"Subjectivity Score\"] = url_subj_score\n",
    "# df[\"Positive Words\"] = total_pos\n",
    "# df[\"Negative Words\"] = total_neg\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82f4f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_sentence_list(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6ed48524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import FastText\n",
    "from gensim import corpora, models\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import re\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import fasttext.util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c46956f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = []\n",
    "input_text = [str(sentence) for sentence in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6fd49b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cc.en.300.bin'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext.util.download_model('en', if_exists='ignore')  # English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14aaf511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft_model = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "439be1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as list of lists of words\n",
    "sentences_ted = []\n",
    "for sent_str in input_text:\n",
    "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent_str.lower()).split()\n",
    "    sentences_ted.append(tokens)\n",
    "\n",
    "stoplist = []\n",
    "with open('stopwords') as openfileobject:\n",
    "    for line in openfileobject:\n",
    "        stoplist.append(line[:-1])\n",
    "stoplist = set(stoplist)\n",
    "\n",
    "for i in range(len(sentences_ted)):\n",
    "    for word in reversed(sentences_ted[i]):\n",
    "        if word in stoplist:\n",
    "            sentences_ted[i].remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2b6fb806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['11',\n",
       "  'minutes',\n",
       "  'aerobics',\n",
       "  'daily',\n",
       "  'lowers',\n",
       "  'disease',\n",
       "  'risk',\n",
       "  'study',\n",
       "  'says',\n",
       "  'cnn',\n",
       "  '11',\n",
       "  'minutes',\n",
       "  'daily',\n",
       "  'exercise',\n",
       "  'could',\n",
       "  'positive',\n",
       "  'impact',\n",
       "  'health',\n",
       "  'large',\n",
       "  'study',\n",
       "  'shows',\n",
       "  'kristen',\n",
       "  'rogers',\n",
       "  'cnn',\n",
       "  'updated',\n",
       "  '6',\n",
       "  '45',\n",
       "  'est',\n",
       "  'wed',\n",
       "  'march',\n",
       "  '1',\n",
       "  '2023',\n",
       "  'link',\n",
       "  'copied'],\n",
       " ['may',\n",
       "  'look',\n",
       "  'silly',\n",
       "  'new',\n",
       "  'study',\n",
       "  'reveals',\n",
       "  'benefits',\n",
       "  'daily',\n",
       "  'routine',\n",
       "  '02',\n",
       "  '34',\n",
       "  'source',\n",
       "  'cnn',\n",
       "  'health',\n",
       "  '16',\n",
       "  'videos',\n",
       "  'may',\n",
       "  'look',\n",
       "  'silly',\n",
       "  'new',\n",
       "  'study',\n",
       "  'reveals',\n",
       "  'benefits',\n",
       "  'daily',\n",
       "  'routine',\n",
       "  '02',\n",
       "  '34',\n",
       "  'playing',\n",
       "  'source'],\n",
       " ['cnn',\n",
       "  'allergies',\n",
       "  'may',\n",
       "  'want',\n",
       "  'avoid',\n",
       "  'type',\n",
       "  'medication',\n",
       "  '02',\n",
       "  '18',\n",
       "  'playing',\n",
       "  'source',\n",
       "  'cnn',\n",
       "  'doctor',\n",
       "  'explains',\n",
       "  'new',\n",
       "  'counter',\n",
       "  'medicine',\n",
       "  'complete',\n",
       "  'antidote',\n",
       "  'opioids',\n",
       "  '01',\n",
       "  '59',\n",
       "  'playing',\n",
       "  'source',\n",
       "  'cnn',\n",
       "  'maternity',\n",
       "  'wards',\n",
       "  'across',\n",
       "  'us',\n",
       "  'closing',\n",
       "  'issue',\n",
       "  '02',\n",
       "  '31',\n",
       "  'playing',\n",
       "  'source',\n",
       "  'cnn',\n",
       "  'nearly',\n",
       "  '40',\n",
       "  'dementia',\n",
       "  'cases',\n",
       "  'prevented',\n",
       "  'one',\n",
       "  'small',\n",
       "  'health',\n",
       "  'change',\n",
       "  '02',\n",
       "  '13',\n",
       "  'playing',\n",
       "  'source',\n",
       "  'cnn',\n",
       "  'type',\n",
       "  'exercise',\n",
       "  'might',\n",
       "  'better',\n",
       "  'brain',\n",
       "  'biking',\n",
       "  'jogging',\n",
       "  '02',\n",
       "  '03',\n",
       "  'playing',\n",
       "  'source',\n",
       "  'cnn',\n",
       "  'toddler',\n",
       "  'suffers',\n",
       "  'disease',\n",
       "  'makes',\n",
       "  'human',\n",
       "  'time',\n",
       "  'bomb',\n",
       "  '05',\n",
       "  '46',\n",
       "  'playing',\n",
       "  'source',\n",
       "  'cnn',\n",
       "  'young',\n",
       "  'model',\n",
       "  'becomes',\n",
       "  'double',\n",
       "  'amputee',\n",
       "  'covid',\n",
       "  '02',\n",
       "  '32',\n",
       "  'playing',\n",
       "  'source',\n",
       "  'cnn',\n",
       "  'sleep',\n",
       "  'specialist',\n",
       "  '4',\n",
       "  'tips',\n",
       "  'help',\n",
       "  'stop',\n",
       "  'snoring',\n",
       "  '01',\n",
       "  '43',\n",
       "  'playing',\n",
       "  'source',\n",
       "  'cnn',\n",
       "  'forgetfulness',\n",
       "  'dementia'],\n",
       " ['doctor',\n",
       "  'finds',\n",
       "  '02',\n",
       "  '53',\n",
       "  'playing',\n",
       "  'source',\n",
       "  'cnn',\n",
       "  'harvard',\n",
       "  'psychiatrist',\n",
       "  'says',\n",
       "  'secret',\n",
       "  'happiness',\n",
       "  '02',\n",
       "  '33',\n",
       "  'playing',\n",
       "  'source',\n",
       "  'cnn',\n",
       "  '95',\n",
       "  'second',\n",
       "  'video',\n",
       "  'help',\n",
       "  'build',\n",
       "  'habit',\n",
       "  'good',\n",
       "  '01',\n",
       "  '35',\n",
       "  'playing',\n",
       "  'source',\n",
       "  'cnn',\n",
       "  'leading',\n",
       "  'us',\n",
       "  'doctor',\n",
       "  'says',\n",
       "  'won',\n",
       "  'get',\n",
       "  'treatment',\n",
       "  'gets',\n",
       "  'cancer',\n",
       "  '75',\n",
       "  '01',\n",
       "  '35',\n",
       "  'playing',\n",
       "  'source',\n",
       "  'cnn',\n",
       "  'mpox'],\n",
       " ['dr',\n",
       "  'gupta',\n",
       "  'explains',\n",
       "  'rare',\n",
       "  'virus',\n",
       "  'spreads',\n",
       "  '02',\n",
       "  '54',\n",
       "  'playing',\n",
       "  'source',\n",
       "  'cnn',\n",
       "  'cnn',\n",
       "  'gets',\n",
       "  'rare',\n",
       "  'inside',\n",
       "  'look',\n",
       "  'nfl',\n",
       "  'protocol',\n",
       "  'saved',\n",
       "  'damar',\n",
       "  'hamlin',\n",
       "  'life',\n",
       "  '05',\n",
       "  '56',\n",
       "  'playing',\n",
       "  'source',\n",
       "  'cnn',\n",
       "  'doctor',\n",
       "  'explains',\n",
       "  'rsv',\n",
       "  'symptoms',\n",
       "  'look',\n",
       "  '01',\n",
       "  '45',\n",
       "  'playing',\n",
       "  'source',\n",
       "  'cnn',\n",
       "  'see',\n",
       "  'videos',\n",
       "  'sign',\n",
       "  'cnn',\n",
       "  'fitness',\n",
       "  'better',\n",
       "  'newsletter',\n",
       "  'series'],\n",
       " ['seven',\n",
       "  'part',\n",
       "  'guide',\n",
       "  'help',\n",
       "  'ease',\n",
       "  'healthy',\n",
       "  'routine',\n",
       "  'backed',\n",
       "  'experts'],\n",
       " ['cnn',\n",
       "  'fit',\n",
       "  'entire',\n",
       "  'workout',\n",
       "  'busy',\n",
       "  'day',\n",
       "  'think',\n",
       "  'point',\n",
       "  'anything'],\n",
       " ['rethink', 'mindset'],\n",
       " ['11',\n",
       "  'minutes',\n",
       "  'moderate',\n",
       "  'vigorous',\n",
       "  'intensity',\n",
       "  'aerobic',\n",
       "  'activity',\n",
       "  'per',\n",
       "  'day',\n",
       "  'could',\n",
       "  'lower',\n",
       "  'risk',\n",
       "  'cancer',\n",
       "  'cardiovascular',\n",
       "  'disease',\n",
       "  'premature',\n",
       "  'death',\n",
       "  'large',\n",
       "  'new',\n",
       "  'study',\n",
       "  'found'],\n",
       " ['aerobic',\n",
       "  'activities',\n",
       "  'include',\n",
       "  'walking',\n",
       "  'dancing',\n",
       "  'running',\n",
       "  'jogging',\n",
       "  'cycling',\n",
       "  'swimming'],\n",
       " ['gauge',\n",
       "  'intensity',\n",
       "  'level',\n",
       "  'activity',\n",
       "  'heart',\n",
       "  'rate',\n",
       "  'hard',\n",
       "  're',\n",
       "  'breathing',\n",
       "  'move'],\n",
       " ['generally',\n",
       "  'able',\n",
       "  'talk',\n",
       "  'sing',\n",
       "  'activity',\n",
       "  'would',\n",
       "  'make',\n",
       "  'moderate',\n",
       "  'intensity'],\n",
       " ['vigorous', 'intensity', 'marked', 'inability', 'carry', 'conversation'],\n",
       " ['higher',\n",
       "  'levels',\n",
       "  'physical',\n",
       "  'activity',\n",
       "  'associated',\n",
       "  'lower',\n",
       "  'rates',\n",
       "  'premature',\n",
       "  'death',\n",
       "  'chronic',\n",
       "  'disease',\n",
       "  'according',\n",
       "  'past',\n",
       "  'research'],\n",
       " ['risk',\n",
       "  'levels',\n",
       "  'outcomes',\n",
       "  'affected',\n",
       "  'amount',\n",
       "  'exercise',\n",
       "  'someone',\n",
       "  'gets',\n",
       "  'difficult',\n",
       "  'determine'],\n",
       " ['explore',\n",
       "  'impact',\n",
       "  'scientists',\n",
       "  'largely',\n",
       "  'university',\n",
       "  'cambridge',\n",
       "  'united',\n",
       "  'kingdom',\n",
       "  'looked',\n",
       "  'data',\n",
       "  '196',\n",
       "  'studies',\n",
       "  'amounting',\n",
       "  '30',\n",
       "  'million',\n",
       "  'adult',\n",
       "  'participants',\n",
       "  'followed',\n",
       "  '10',\n",
       "  'years',\n",
       "  'average'],\n",
       " ['results',\n",
       "  'latest',\n",
       "  'study',\n",
       "  'published',\n",
       "  'tuesday',\n",
       "  'british',\n",
       "  'journal',\n",
       "  'sports',\n",
       "  'medicine'],\n",
       " ['adding',\n",
       "  '11',\n",
       "  'minutes',\n",
       "  'exercise',\n",
       "  'day',\n",
       "  'could',\n",
       "  'lower',\n",
       "  'risk',\n",
       "  'chronic',\n",
       "  'disease',\n",
       "  'death',\n",
       "  'new',\n",
       "  'research',\n",
       "  'found'],\n",
       " ['li',\n",
       "  'zhongfei',\n",
       "  'adobe',\n",
       "  'stock',\n",
       "  'study',\n",
       "  'mainly',\n",
       "  'focused',\n",
       "  'participants',\n",
       "  'done',\n",
       "  'minimum',\n",
       "  'recommended',\n",
       "  'amount',\n",
       "  '150',\n",
       "  'minutes',\n",
       "  'exercise',\n",
       "  'per',\n",
       "  'week',\n",
       "  '22',\n",
       "  'minutes',\n",
       "  'per',\n",
       "  'day'],\n",
       " ['compared',\n",
       "  'inactive',\n",
       "  'participants',\n",
       "  'adults',\n",
       "  'done',\n",
       "  '150',\n",
       "  'minutes',\n",
       "  'moderate',\n",
       "  'vigorous',\n",
       "  'aerobic',\n",
       "  'physical',\n",
       "  'activity',\n",
       "  'per',\n",
       "  'week',\n",
       "  '31',\n",
       "  'lower',\n",
       "  'risk',\n",
       "  'dying',\n",
       "  'cause',\n",
       "  '29',\n",
       "  'lower',\n",
       "  'risk',\n",
       "  'dying',\n",
       "  'cardiovascular',\n",
       "  'disease',\n",
       "  '15',\n",
       "  'lower',\n",
       "  'risk',\n",
       "  'dying',\n",
       "  'cancer'],\n",
       " ['amount',\n",
       "  'exercise',\n",
       "  'linked',\n",
       "  '27',\n",
       "  'lower',\n",
       "  'risk',\n",
       "  'developing',\n",
       "  'cardiovascular',\n",
       "  'disease',\n",
       "  '12',\n",
       "  'lower',\n",
       "  'risk',\n",
       "  'came',\n",
       "  'cancer'],\n",
       " ['compelling',\n",
       "  'systematic',\n",
       "  'review',\n",
       "  'existing',\n",
       "  'research',\n",
       "  'said',\n",
       "  'cnn',\n",
       "  'medical',\n",
       "  'analyst',\n",
       "  'dr',\n",
       "  'leana',\n",
       "  'wen',\n",
       "  'emergency',\n",
       "  'physician',\n",
       "  'public',\n",
       "  'health',\n",
       "  'professor',\n",
       "  'george',\n",
       "  'washington',\n",
       "  'university',\n",
       "  'wasn',\n",
       "  'involved',\n",
       "  'research'],\n",
       " ['already',\n",
       "  'knew',\n",
       "  'strong',\n",
       "  'correlation',\n",
       "  'increased',\n",
       "  'physical',\n",
       "  'activity',\n",
       "  'reduced',\n",
       "  'risk',\n",
       "  'cardiovascular',\n",
       "  'disease',\n",
       "  'cancer',\n",
       "  'premature',\n",
       "  'death'],\n",
       " ['research',\n",
       "  'confirms',\n",
       "  'furthermore',\n",
       "  'states',\n",
       "  'smaller',\n",
       "  'amount',\n",
       "  '150',\n",
       "  'minutes',\n",
       "  'recommended',\n",
       "  'exercise',\n",
       "  'week',\n",
       "  'help',\n",
       "  'even',\n",
       "  'people',\n",
       "  'got',\n",
       "  'half',\n",
       "  'minimum',\n",
       "  'recommended',\n",
       "  'amount',\n",
       "  'physical',\n",
       "  'activity',\n",
       "  'benefited'],\n",
       " ['accumulating',\n",
       "  '75',\n",
       "  'minutes',\n",
       "  'moderate',\n",
       "  'intensity',\n",
       "  'activity',\n",
       "  'per',\n",
       "  'week',\n",
       "  '11',\n",
       "  'minutes',\n",
       "  'activity',\n",
       "  'per',\n",
       "  'day',\n",
       "  'associated',\n",
       "  '23',\n",
       "  'lower',\n",
       "  'risk',\n",
       "  'early',\n",
       "  'death'],\n",
       " ['getting',\n",
       "  'active',\n",
       "  '75',\n",
       "  'minutes',\n",
       "  'weekly',\n",
       "  'basis',\n",
       "  'also',\n",
       "  'enough',\n",
       "  'reduce',\n",
       "  'risk',\n",
       "  'developing',\n",
       "  'cardiovascular',\n",
       "  'disease',\n",
       "  '17',\n",
       "  'cancer',\n",
       "  '7'],\n",
       " ['adobe',\n",
       "  'stock',\n",
       "  'irregular',\n",
       "  'sleep',\n",
       "  'may',\n",
       "  'harmful',\n",
       "  'heart',\n",
       "  'study',\n",
       "  'finds',\n",
       "  'beyond',\n",
       "  '150',\n",
       "  'minutes',\n",
       "  'per',\n",
       "  'week',\n",
       "  'additional',\n",
       "  'benefits',\n",
       "  'smaller'],\n",
       " ['someone',\n",
       "  'finds',\n",
       "  'idea',\n",
       "  '150',\n",
       "  'minutes',\n",
       "  'moderate',\n",
       "  'intensity',\n",
       "  'physical',\n",
       "  'activity',\n",
       "  'week',\n",
       "  'bit',\n",
       "  'daunting',\n",
       "  'findings',\n",
       "  'good',\n",
       "  'news',\n",
       "  'said',\n",
       "  'study',\n",
       "  'author',\n",
       "  'dr',\n",
       "  'soren',\n",
       "  'brage',\n",
       "  'group',\n",
       "  'leader',\n",
       "  'physical',\n",
       "  'activity',\n",
       "  'epidemiology',\n",
       "  'group',\n",
       "  'medical',\n",
       "  'research',\n",
       "  'council',\n",
       "  'epidemiology',\n",
       "  'unit',\n",
       "  'university',\n",
       "  'cambridge',\n",
       "  'news',\n",
       "  'release'],\n",
       " ['also',\n",
       "  'good',\n",
       "  'starting',\n",
       "  'position',\n",
       "  'find',\n",
       "  '75',\n",
       "  'minutes',\n",
       "  'week',\n",
       "  'manageable',\n",
       "  'could',\n",
       "  'try',\n",
       "  'stepping',\n",
       "  'gradually',\n",
       "  'full',\n",
       "  'recommended',\n",
       "  'amount'],\n",
       " ['authors',\n",
       "  'findings',\n",
       "  'affirm',\n",
       "  'world',\n",
       "  'health',\n",
       "  'organization',\n",
       "  'position',\n",
       "  'physical',\n",
       "  'activity',\n",
       "  'better',\n",
       "  'none',\n",
       "  'even',\n",
       "  'get',\n",
       "  'recommended',\n",
       "  'amounts',\n",
       "  'exercise'],\n",
       " ['one',\n",
       "  '10',\n",
       "  'premature',\n",
       "  'deaths',\n",
       "  'could',\n",
       "  'prevented',\n",
       "  'everyone',\n",
       "  'achieved',\n",
       "  'even',\n",
       "  'half',\n",
       "  'recommended',\n",
       "  'level',\n",
       "  'physical',\n",
       "  'activity',\n",
       "  'authors',\n",
       "  'wrote',\n",
       "  'study'],\n",
       " ['additionally',\n",
       "  '10',\n",
       "  '9',\n",
       "  '5',\n",
       "  '2',\n",
       "  'incident',\n",
       "  'cases',\n",
       "  'cvd',\n",
       "  'cardiovascular',\n",
       "  'disease',\n",
       "  'cancer',\n",
       "  'would',\n",
       "  'prevented'],\n",
       " ['important',\n",
       "  'note',\n",
       "  'experience',\n",
       "  'pain',\n",
       "  'exercising',\n",
       "  'stop',\n",
       "  'immediately'],\n",
       " ['check', 'doctor', 'beginning', 'new', 'exercise', 'program'],\n",
       " ['little',\n",
       "  'exercise',\n",
       "  'every',\n",
       "  'day',\n",
       "  'authors',\n",
       "  'didn',\n",
       "  'details',\n",
       "  'specific',\n",
       "  'types',\n",
       "  'physical',\n",
       "  'activity',\n",
       "  'participants'],\n",
       " ['experts',\n",
       "  'thoughts',\n",
       "  'physical',\n",
       "  'activity',\n",
       "  'could',\n",
       "  'reduce',\n",
       "  'risk',\n",
       "  'chronic',\n",
       "  'diseases',\n",
       "  'premature',\n",
       "  'death'],\n",
       " ['many',\n",
       "  'potential',\n",
       "  'mechanisms',\n",
       "  'including',\n",
       "  'improvement',\n",
       "  'maintenance',\n",
       "  'body',\n",
       "  'composition',\n",
       "  'insulin',\n",
       "  'resistance',\n",
       "  'physical',\n",
       "  'function',\n",
       "  'wide',\n",
       "  'variety',\n",
       "  'favorable',\n",
       "  'influences',\n",
       "  'aerobic',\n",
       "  'activity',\n",
       "  'said',\n",
       "  'haruki',\n",
       "  'momma',\n",
       "  'associate',\n",
       "  'professor',\n",
       "  'medicine',\n",
       "  'science',\n",
       "  'sports',\n",
       "  'exercise',\n",
       "  'tohoku',\n",
       "  'university',\n",
       "  'japan'],\n",
       " ['momma', 'wasn', 'involved', 'research'],\n",
       " ['benefits',\n",
       "  'could',\n",
       "  'also',\n",
       "  'include',\n",
       "  'improvement',\n",
       "  'immune',\n",
       "  'function',\n",
       "  'lung',\n",
       "  'heart',\n",
       "  'health',\n",
       "  'inflammation',\n",
       "  'levels',\n",
       "  'hypertension',\n",
       "  'cholesterol',\n",
       "  'amount',\n",
       "  'body',\n",
       "  'fat',\n",
       "  'said',\n",
       "  'eleanor',\n",
       "  'watts',\n",
       "  'postdoctoral',\n",
       "  'fellow',\n",
       "  'division',\n",
       "  'cancer',\n",
       "  'epidemiology',\n",
       "  'genetics',\n",
       "  'national',\n",
       "  'cancer',\n",
       "  'institute'],\n",
       " ['watts', 'wasn', 'involved', 'research'],\n",
       " ['photo',\n",
       "  'illustration',\n",
       "  'leah',\n",
       "  'abucayan',\n",
       "  'get',\n",
       "  'moving',\n",
       "  'faster',\n",
       "  'cardio',\n",
       "  'reboot',\n",
       "  'workout',\n",
       "  'routine',\n",
       "  'translate',\n",
       "  'lower',\n",
       "  'risk',\n",
       "  'getting',\n",
       "  'chronic',\n",
       "  'diseases',\n",
       "  'said',\n",
       "  'peter',\n",
       "  'katzmarzyk',\n",
       "  'associate',\n",
       "  'executive',\n",
       "  'director',\n",
       "  'population',\n",
       "  'public',\n",
       "  'health',\n",
       "  'sciences',\n",
       "  'pennington',\n",
       "  'biomedical',\n",
       "  'research',\n",
       "  'center',\n",
       "  'baton',\n",
       "  'rouge',\n",
       "  'louisiana'],\n",
       " ['katzmarzyk', 'wasn', 'involved', 'research'],\n",
       " ['fact',\n",
       "  'participants',\n",
       "  'half',\n",
       "  'minimum',\n",
       "  'recommended',\n",
       "  'amount',\n",
       "  'exercise',\n",
       "  'still',\n",
       "  'experienced',\n",
       "  'benefits',\n",
       "  'doesn',\n",
       "  'mean',\n",
       "  'people',\n",
       "  'shouldn',\n",
       "  'aim',\n",
       "  'exercise',\n",
       "  'rather',\n",
       "  'perfect',\n",
       "  'shouldn',\n",
       "  'enemy',\n",
       "  'good',\n",
       "  'wen',\n",
       "  'said'],\n",
       " ['better', 'none'],\n",
       " ['get',\n",
       "  '150',\n",
       "  'minutes',\n",
       "  'physical',\n",
       "  'activity',\n",
       "  'per',\n",
       "  'week',\n",
       "  'find',\n",
       "  'activities',\n",
       "  'enjoy',\n",
       "  'wen',\n",
       "  'said'],\n",
       " ['far', 'likely', 'engage', 'something', 'love', 'something', 'make'],\n",
       " ['comes', 'fit', 'exercise', 'think', 'outside', 'box'],\n",
       " ['moderate',\n",
       "  'activity',\n",
       "  'doesn',\n",
       "  'involve',\n",
       "  'normally',\n",
       "  'think',\n",
       "  'exercise',\n",
       "  'sports',\n",
       "  'running',\n",
       "  'said',\n",
       "  'study',\n",
       "  'coauthor',\n",
       "  'leandro',\n",
       "  'garcia',\n",
       "  'lecturer',\n",
       "  'school',\n",
       "  'medicine',\n",
       "  'dentistry',\n",
       "  'biomedical',\n",
       "  'sciences',\n",
       "  'queen',\n",
       "  'university',\n",
       "  'belfast',\n",
       "  'news',\n",
       "  'release'],\n",
       " ['sometimes', 'replacing', 'habits', 'needed'],\n",
       " ['example',\n",
       "  'try',\n",
       "  'walk',\n",
       "  'cycle',\n",
       "  'work',\n",
       "  'study',\n",
       "  'place',\n",
       "  'instead',\n",
       "  'using',\n",
       "  'car',\n",
       "  'engage',\n",
       "  'active',\n",
       "  'play',\n",
       "  'kids',\n",
       "  'grand',\n",
       "  'kids'],\n",
       " ['activities',\n",
       "  'enjoy',\n",
       "  'easy',\n",
       "  'include',\n",
       "  'weekly',\n",
       "  'routine',\n",
       "  'excellent',\n",
       "  'way',\n",
       "  'become',\n",
       "  'active'],\n",
       " ['related']]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_ted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "84d6d851",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 474 is out of bounds for axis 1 with size 474",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19796\\722895103.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences_ted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_extremes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_below\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_above\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mlda_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLdaModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbow_corpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\biehl\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m             self.add_lifecycle_event(\n\u001b[0;32m    522\u001b[0m                 \u001b[1;34m\"created\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\biehl\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0meval_every\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreallen\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_no\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0meval_every\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumworkers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_perplexity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_docs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlencorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\biehl\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mlog_perplexity\u001b[1;34m(self, chunk, total_docs)\u001b[0m\n\u001b[0;32m    844\u001b[0m         \u001b[0mcorpus_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m         \u001b[0msubsample_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtotal_docs\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 846\u001b[1;33m         \u001b[0mperwordbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsample_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubsample_ratio\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msubsample_ratio\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcorpus_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m         logger.info(\n\u001b[0;32m    848\u001b[0m             \u001b[1;34m\"%.3f per-word bound, %.1f perplexity estimate based on a held-out corpus of %i documents with %i words\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\biehl\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mbound\u001b[1;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[0;32m   1110\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bound: at document #%i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m                 \u001b[0mgammad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1113\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m                 \u001b[0mgammad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\biehl\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[0mElogthetad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mElogtheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m             \u001b[0mexpElogthetad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpElogtheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m             \u001b[0mexpElogbetad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpElogbeta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m             \u001b[1;31m# The optimal phi_{dwk} is proportional to expElogthetad_k * expElogbetad_kw.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 474 is out of bounds for axis 1 with size 474"
     ]
    }
   ],
   "source": [
    "#model = FastText(vector_size=500, window=2, min_count=1)  # instantiate\n",
    "#model.build_vocab(corpus_iterable=sentences_ted)\n",
    "#model.train(corpus_iterable=sentences_ted, total_examples=len(sentences_ted), epochs=50)  # train\n",
    "num_topics = 10\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in sentences_ted]\n",
    "dictionary = Dictionary(sentences_ted)\n",
    "dictionary.filter_extremes(no_below=0.1, no_above=0.9)\n",
    "lda_model = LdaModel(bow_corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9ccd72d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"out.txt\", \"w\")\n",
    "for topic_id in range(num_topics):\n",
    "    file.write(f\"Topic {topic_id + 1}:\\n\")\n",
    "    for term, weight in lda_model.show_topic(topic_id):\n",
    "        file.write(f\"\\t{term}: {weight}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ca43d10",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19796\\1376554367.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"students\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.wv.most_similar(\"students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('system', 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b699f78",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FastText' object has no attribute 'show_topics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m topics \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mshow_topics(num_topics\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, formatted\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FastText' object has no attribute 'show_topics'"
     ]
    }
   ],
   "source": [
    "topics = model.show_topics(num_topics=-1, formatted=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CPTS421",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
